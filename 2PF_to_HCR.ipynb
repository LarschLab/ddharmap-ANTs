{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1eb3fd5",
   "metadata": {},
   "source": [
    "\n",
    "# Functional → Anatomy → HCR Mapping (Zebrafish, 2P + HCR)\n",
    "\n",
    "This notebook automates a practical pipeline to map motion-corrected functional planes to the best matching **2P anatomy** Z-plane and then into **HCR/confocal** space.\n",
    "\n",
    "**Core steps**\n",
    "1. Build a *crisp* per-plane functional reference using a Suite2p-style **top‑correlated mean**.\n",
    "2. For each plane, find the **best matching Z** in the 2P anatomy stack via **normalized cross‑correlation**.\n",
    "3. Estimate an **in‑plane transform** (shift/similarity) from functional reference → anatomy[best‑Z].\n",
    "4. Apply a precomputed **3D warp** (anatomy → HCR) to place the functional plane/slab into HCR space.\n",
    "5. Transfer **ROI labels** (nearest‑neighbor) or **fluorescence images** (linear) as appropriate.\n",
    "\n",
    "> Tip: Set the voxel sizes (µm) correctly for both stacks before registration, and keep a record of transforms so you can compose and resample **once** wherever possible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a2f028",
   "metadata": {},
   "source": [
    "\n",
    "## Requirements\n",
    "\n",
    "This notebook uses common scientific Python packages:\n",
    "\n",
    "- `numpy`, `scipy`, `pandas`\n",
    "- `tifffile`\n",
    "- `scikit-image` (`skimage`)\n",
    "- `opencv-python` (optional; speeds up template matching)\n",
    "- `matplotlib` for quick QA plots\n",
    "\n",
    "If an import fails, install the package in your environment and re-run the cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a88d88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, json, math, random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tifffile import imread, imwrite, TiffFile\n",
    "from skimage import filters, exposure, transform, feature, measure, registration, img_as_float32\n",
    "from skimage.transform import SimilarityTransform, AffineTransform, warp\n",
    "from skimage.util import img_as_ubyte\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "# Optional OpenCV (accelerated NCC); guarded import\n",
    "try:\n",
    "    import cv2\n",
    "    HAS_CV2 = True\n",
    "except Exception:\n",
    "    HAS_CV2 = False\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"HAS_CV2:\", HAS_CV2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdfe6de",
   "metadata": {},
   "source": [
    "\n",
    "## Paths & I/O\n",
    "\n",
    "Edit these to your data. You can also point to your colleague's helper notebook (`/mnt/data/fToA_registration_jl.ipynb`) if you want to copy functions from it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79034d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- User paths (EDIT ME) ---\n",
    "INPUT_DIR = Path('/Users/ddharmap/dataProcessing/2p_HCR/analysis/2pf-2pa/input')\n",
    "OUTDIR = Path('/Users/ddharmap/dataProcessing/2p_HCR/analysis/2pf-2pa/output'); OUTDIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Default input files inside INPUT_DIR\n",
    "FUNC_STACK_PATH = INPUT_DIR / 'L395_f11_plane0_mcorrected_flipX_substack.tif'   # motion-corrected, single plane over time OR volume over time\n",
    "ANAT_STACK_PATH = INPUT_DIR / 'L395_f11_anatomy_2P_GCaMP.tif'   # 2P anatomy (structural) stack\n",
    "# HCR_STACK_PATH  = INPUT_DIR / 'hcr_stack.tif'          # HCR/confocal stack (already cleared sample)\n",
    "\n",
    "# Optional label image to map (e.g., Cellpose labels)\n",
    "LABELS_PATH = None   # e.g., INPUT_DIR / 'cellpose_labels.tif' (uint16 IDs)\n",
    "\n",
    "# Cellpose/segmentation masks (functional 2D, anatomy 3D)\n",
    "FUNC_LABELS_PATH = INPUT_DIR / 'AVG_L395_f11_plane0_mcorrected_flipX_substack_cp_masks.png'   # per-pixel int IDs (0=bg)\n",
    "ANAT_LABELS_PATH = INPUT_DIR / 'L395_f11_anatomy_00001_8bit_cp_masks.tif'   # 3D labels stack (Z,Y,X)\n",
    "\n",
    "# Voxel sizes are inferred from image metadata and cached (see next cell).\n",
    "\n",
    "# Reference building strategy for functional plane: 'time_mean' or 'topcorr'\n",
    "REF_BUILD_STRATEGY = globals().get('REF_BUILD_STRATEGY', 'time_mean')\n",
    "# Toggle: if True, rescale functional reference to anatomy XY before NCC (can blur and sometimes hurt feature matching).\n",
    "RESCALE_FOR_NCC = False\n",
    "# If detection fails or you want to override, set these manual values (µm). Leave None to skip an axis.\n",
    "VOX_FUNC_MANUAL = { 'X': 0.6166852, 'Y': 0.6166852 }  # functional (XY only)\n",
    "VOX_ANAT_MANUAL = { 'X': 0.5964025, 'Y': 0.5964025, 'Z': 2.0 } # anatomy (XYZ)\n",
    "\n",
    "# Random seed for reproducibility in frame subsampling\n",
    "RNG_SEED = 42\n",
    "random.seed(RNG_SEED)\n",
    "np.random.seed(RNG_SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e11d7e2",
   "metadata": {},
   "source": [
    "\n",
    "## Utility functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000291a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def zproject_mean(stack):\n",
    "    return stack.mean(axis=0)\n",
    "\n",
    "def norm01(img):\n",
    "    img = img.astype(np.float32)\n",
    "    m, M = np.percentile(img, (1, 99))\n",
    "    if M <= m:\n",
    "        M = img.max(); m = img.min()\n",
    "    out = np.clip((img - m) / (M - m + 1e-6), 0, 1)\n",
    "    return out\n",
    "\n",
    "def local_unsharp(img, blur_sigma=1.0, amount=0.6):\n",
    "    base = ndi.gaussian_filter(img, blur_sigma)\n",
    "    return np.clip(base + amount*(img - base), 0, 1)\n",
    "\n",
    "def corrcoef_img(a, b):\n",
    "    # Pearson correlation between 2D arrays\n",
    "    a = a.astype(np.float32); b = b.astype(np.float32)\n",
    "    am = a.mean(); bm = b.mean()\n",
    "    num = ((a - am)*(b - bm)).sum()\n",
    "    den = np.sqrt(((a - am)**2).sum() * ((b - bm)**2).sum()) + 1e-8\n",
    "    return float(num / den)\n",
    "\n",
    "def top_correlated_mean(stack_t, take_k=20, pre_smooth_sigma=0.5):\n",
    "    \"\"\"Suite2p-like: build crisp reference by selecting top-K frames most correlated to a provisional mean.\"\"\"\n",
    "    T, H, W = stack_t.shape\n",
    "    # Provisional mean\n",
    "    m0 = stack_t.mean(axis=0)\n",
    "    # Optional pre-smoothing to reduce shot noise\n",
    "    if pre_smooth_sigma and pre_smooth_sigma > 0:\n",
    "        m0s = ndi.gaussian_filter(m0, pre_smooth_sigma)\n",
    "    else:\n",
    "        m0s = m0\n",
    "    # Correlate each frame with provisional mean\n",
    "    corrs = np.empty(T, dtype=np.float32)\n",
    "    for i in range(T):\n",
    "        fi = stack_t[i]\n",
    "        if pre_smooth_sigma and pre_smooth_sigma > 0:\n",
    "            fi = ndi.gaussian_filter(fi, pre_smooth_sigma)\n",
    "        corrs[i] = corrcoef_img(fi, m0s)\n",
    "    # Take top-K\n",
    "    k = min(take_k, T)\n",
    "    idx = np.argsort(corrs)[-k:]\n",
    "    ref = stack_t[idx].mean(axis=0)\n",
    "    return ref, idx, corrs\n",
    "\n",
    "def best_z_by_ncc(template, anat_stack, use_cv2=True):\n",
    "    \"\"\"Return best Z index and NCC scores over Z for a 2D template vs 3D stack.\"\"\"\n",
    "    template = norm01(template)\n",
    "    H, W = template.shape\n",
    "    scores = []\n",
    "    if use_cv2 and HAS_CV2:\n",
    "        templ = (template*255).astype(np.uint8)\n",
    "        for z in range(anat_stack.shape[0]):\n",
    "            sl = norm01(anat_stack[z])\n",
    "            sl8 = (sl*255).astype(np.uint8)\n",
    "            res = cv2.matchTemplate(sl8, templ, cv2.TM_CCORR_NORMED)\n",
    "            # Whole-image match: template same size; if not, pad template or crop; here we assume same FOV/size\n",
    "            if res.size == 1:\n",
    "                s = float(res.ravel()[0])\n",
    "            else:\n",
    "                s = float(res.max())\n",
    "            scores.append(s)\n",
    "    else:\n",
    "        # fallback: simple correlation on same-size images\n",
    "        for z in range(anat_stack.shape[0]):\n",
    "            sl = norm01(anat_stack[z])\n",
    "            s = corrcoef_img(template, sl)\n",
    "            scores.append(s)\n",
    "    scores = np.asarray(scores, dtype=np.float32)\n",
    "    best_z = int(np.argmax(scores))\n",
    "    return best_z, scores\n",
    "\n",
    "def estimate_inplane_transform(mov, ref, method='similarity'):\n",
    "    \"\"\"Estimate 2D transform from moving image (mov) to reference (ref).\n",
    "    Tries ORB+RANSAC; falls back to phase cross-correlation (shift only).\"\"\"\n",
    "    m = norm01(mov); r = norm01(ref)\n",
    "    # ORB keypoints\n",
    "    try:\n",
    "        detector = feature.ORB(n_keypoints=2000, fast_threshold=0.05)\n",
    "        detector.detect_and_extract(img_as_float32(m))\n",
    "        kp1 = detector.keypoints; d1 = detector.descriptors\n",
    "        detector.detect_and_extract(img_as_float32(r))\n",
    "        kp2 = detector.keypoints; d2 = detector.descriptors\n",
    "        if len(kp1) >= 10 and len(kp2) >= 10 and d1 is not None and d2 is not None:\n",
    "            matches12 = feature.match_descriptors(d1, d2, cross_check=True, max_ratio=0.8)\n",
    "            src = kp1[matches12[:, 0]][:, ::-1]  # (x,y)\n",
    "            dst = kp2[matches12[:, 1]][:, ::-1]\n",
    "            if method == 'similarity':\n",
    "                model, inliers = measure.ransac((src, dst), SimilarityTransform,\n",
    "                                                min_samples=3, residual_threshold=2.0, max_trials=2000)\n",
    "            else:\n",
    "                model, inliers = measure.ransac((src, dst), AffineTransform,\n",
    "                                                min_samples=3, residual_threshold=2.0, max_trials=2000)\n",
    "            if model is not None:\n",
    "                return model\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    # Fallback: phase correlation for shift\n",
    "    shift, _, _ = registration.phase_cross_correlation(r, m, upsample_factor=10)\n",
    "    tform = SimilarityTransform(translation=(shift[1], shift[0]))\n",
    "    return tform\n",
    "\n",
    "def refine_affine_ecc(mov, ref, init_tform=None, max_iters=200, eps=1e-6, pyr_levels=3):\n",
    "    \"\"\"Refine an in-plane transform with OpenCV ECC (intensity-based), using affine model.\n",
    "    Returns an AffineTransform that maps mov → ref.\n",
    "    Strategy: pre-warp mov with init_tform into ref-shape, then run ECC starting from identity; compose.\n",
    "    \"\"\"\n",
    "    if not HAS_CV2:\n",
    "        return init_tform if init_tform is not None else AffineTransform()\n",
    "    r = img_as_float32(norm01(ref))\n",
    "    # Pre-warp moving with init transform to match ref shape (if provided)\n",
    "    if init_tform is None:\n",
    "        m0 = img_as_float32(norm01(mov))\n",
    "        if m0.shape != r.shape:\n",
    "            m0 = transform.resize(m0, r.shape, order=1, preserve_range=True, anti_aliasing=True).astype(np.float32)\n",
    "        W_init = np.eye(3, dtype=np.float32)\n",
    "    else:\n",
    "        m0 = apply_transform_2d(img_as_float32(norm01(mov)), init_tform, output_shape=r.shape, order=1)\n",
    "        W_init = init_tform.params.astype(np.float32)\n",
    "    # ECC from identity\n",
    "    W_ecc = np.eye(2, 3, dtype=np.float32)\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, int(max_iters), float(eps))\n",
    "    try:\n",
    "        cc, Wopt = cv2.findTransformECC(r, m0, W_ecc, cv2.MOTION_AFFINE, criteria, None, pyr_levels)\n",
    "        A_ecc = np.eye(3, dtype=np.float32); A_ecc[:2, :]= Wopt\n",
    "        # Compose: first init, then ECC refinement in ref frame\n",
    "        A_final = A_ecc @ W_init\n",
    "        return AffineTransform(matrix=A_final)\n",
    "    except Exception:\n",
    "        return init_tform if init_tform is not None else AffineTransform()\n",
    "\n",
    "def apply_transform_2d(img, tform, output_shape=None, order=1, preserve_range=True):\n",
    "    if output_shape is None:\n",
    "        output_shape = img.shape\n",
    "    warped = warp(img, inverse_map=tform.inverse, output_shape=output_shape, order=order,\n",
    "                  preserve_range=preserve_range, mode='constant', cval=0.0, clip=True)\n",
    "    return warped\n",
    "\n",
    "def resample_labels_nn(img, tform, output_shape=None):\n",
    "    # nearest-neighbor for label images\n",
    "    return apply_transform_2d(img, tform, output_shape=output_shape, order=0, preserve_range=True)\n",
    "\n",
    "def apply_anat_to_hcr_warp_2d(slice_img, z_index, warp3d_func):\n",
    "    \"\"\"Hook to apply a 3D warp (anatomy→HCR) to a 2D slice.\n",
    "    `warp3d_func` should accept (z,y,x) indices or coordinates and return warped image in HCR coords.\n",
    "    For now this is a placeholder you can implement with your BigWarp/ANTs output.\n",
    "    \"\"\"\n",
    "    return warp3d_func(slice_img, z_index)\n",
    "\n",
    "def quickshow(img, title='', vmin=None, vmax=None):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(img, vmin=vmin, vmax=vmax)\n",
    "    plt.title(title); plt.axis('off'); plt.show()\n",
    "\n",
    "def _to_um(val, unit):\n",
    "    try:\n",
    "        v = float(val)\n",
    "    except Exception:\n",
    "        return None\n",
    "    if unit is None:\n",
    "        return None\n",
    "    u = str(unit).lower()\n",
    "    if u in ('µm', 'um', 'micron', 'micrometer', 'micrometre'):\n",
    "        return v\n",
    "    if u in ('nm', 'nanometer', 'nanometre'):\n",
    "        return v / 1000.0\n",
    "    if u in ('mm', 'millimeter', 'millimetre'):\n",
    "        return v * 1000.0\n",
    "    if u in ('cm', 'centimeter', 'centimetre'):\n",
    "        return v * 10000.0\n",
    "    if u in ('in', 'inch', 'inches'):\n",
    "        return v * 25400.0\n",
    "    return None\n",
    "\n",
    "def _res_to_um_per_px(res_tag, unit_tag):\n",
    "    try:\n",
    "        num, den = getattr(res_tag, 'value', (None, None))\n",
    "        if num is None or den is None:\n",
    "            v = float(getattr(res_tag, 'value', None))\n",
    "            ppu = v\n",
    "        else:\n",
    "            ppu = float(num) / float(den)\n",
    "    except Exception:\n",
    "        return None\n",
    "    unit_val = getattr(unit_tag, 'value', unit_tag)\n",
    "    try:\n",
    "        u = str(unit_val).upper()\n",
    "    except Exception:\n",
    "        u = 'NONE'\n",
    "    if u == '2' or 'INCH' in u:\n",
    "        return 25400.0 / ppu\n",
    "    if u == '3' or 'CENTIMETER' in u or 'CM' in u:\n",
    "        return 10000.0 / ppu\n",
    "    return None\n",
    "\n",
    "def infer_voxels_tiff(path):\n",
    "    vox = {'Z': None, 'Y': None, 'X': None}\n",
    "    try:\n",
    "        with TiffFile(str(path)) as tf:\n",
    "            # OME-XML\n",
    "            omexml = None\n",
    "            try:\n",
    "                omexml = tf.ome_metadata\n",
    "            except Exception:\n",
    "                omexml = None\n",
    "            if omexml:\n",
    "                try:\n",
    "                    import xml.etree.ElementTree as ET\n",
    "                    root = ET.fromstring(omexml)\n",
    "                    # find any Pixels element regardless of namespace\n",
    "                    pix = root.find('.//{*}Pixels')\n",
    "                    if pix is not None:\n",
    "                        px = pix.attrib.get('PhysicalSizeX'); pxu = pix.attrib.get('PhysicalSizeXUnit')\n",
    "                        py = pix.attrib.get('PhysicalSizeY'); pyu = pix.attrib.get('PhysicalSizeYUnit')\n",
    "                        pz = pix.attrib.get('PhysicalSizeZ'); pzu = pix.attrib.get('PhysicalSizeZUnit')\n",
    "                        if py is not None:\n",
    "                            v = _to_um(py, pyu or 'um')\n",
    "                            if v: vox['Y'] = v\n",
    "                        if px is not None:\n",
    "                            v = _to_um(px, pxu or 'um')\n",
    "                            if v: vox['X'] = v\n",
    "                        if pz is not None:\n",
    "                            v = _to_um(pz, pzu or 'um')\n",
    "                            if v: vox['Z'] = v\n",
    "                except Exception:\n",
    "                    pass\n",
    "            # ImageJ metadata (Z spacing)\n",
    "            try:\n",
    "                ij = tf.imagej_metadata or {}\n",
    "                if isinstance(ij, dict):\n",
    "                    zsp = ij.get('spacing', None)\n",
    "                    unit = ij.get('unit', 'um')\n",
    "                    if vox['Z'] is None and zsp is not None:\n",
    "                        vz = _to_um(zsp, unit)\n",
    "                        if vz: vox['Z'] = vz\n",
    "            except Exception:\n",
    "                pass\n",
    "            # Resolution tags → X/Y\n",
    "            try:\n",
    "                page0 = tf.pages[0]\n",
    "                xr = page0.tags.get('XResolution', None)\n",
    "                yr = page0.tags.get('YResolution', None)\n",
    "                ru = page0.tags.get('ResolutionUnit', None)\n",
    "                if vox['X'] is None and xr is not None and ru is not None:\n",
    "                    vx = _res_to_um_per_px(xr, ru)\n",
    "                    if vx: vox['X'] = vx\n",
    "                if vox['Y'] is None and yr is not None and ru is not None:\n",
    "                    vy = _res_to_um_per_px(yr, ru)\n",
    "                    if vy: vox['Y'] = vy\n",
    "            except Exception:\n",
    "                pass\n",
    "            # Parse ImageDescription for XY pixel size if still missing\n",
    "            try:\n",
    "                page0 = tf.pages[0]\n",
    "                desc = None\n",
    "                try:\n",
    "                    desc = page0.description\n",
    "                except Exception:\n",
    "                    pass\n",
    "                if desc is None:\n",
    "                    try:\n",
    "                        tag = page0.tags.get('ImageDescription', None)\n",
    "                        desc = getattr(tag, 'value', None)\n",
    "                    except Exception:\n",
    "                        desc = None\n",
    "                if desc is not None:\n",
    "                    try:\n",
    "                        text = desc.decode('utf-8', 'ignore') if isinstance(desc, (bytes, bytearray)) else str(desc)\n",
    "                    except Exception:\n",
    "                        text = str(desc)\n",
    "                    kv = {}\n",
    "                    for line in text.replace('\\r', '\\n').split('\\n'):\n",
    "                        if '=' in line:\n",
    "                            k, v = line.split('=', 1)\n",
    "                            kv[k.strip()] = v.strip()\n",
    "                    unit = kv.get('unit', kv.get('Unit', 'um'))\n",
    "                    px = kv.get('pixelWidth') or kv.get('PixelWidth') or kv.get('XPixelSize') or kv.get('micronsPerPixelX') or kv.get('MicronsPerPixelX') or kv.get('umPerPixelX') or kv.get('UmPerPixelX') or kv.get('X_UM_PER_PIXEL')\n",
    "                    py = kv.get('pixelHeight') or kv.get('PixelHeight') or kv.get('YPixelSize') or kv.get('micronsPerPixelY') or kv.get('MicronsPerPixelY') or kv.get('umPerPixelY') or kv.get('UmPerPixelY') or kv.get('Y_UM_PER_PIXEL')\n",
    "                    both = kv.get('PixelSizeUm') or kv.get('pixelSizeUm') or kv.get('PixelSize')\n",
    "                    if both is not None:\n",
    "                        try:\n",
    "                            val = float(both)\n",
    "                            if vox['X'] is None: vox['X'] = val\n",
    "                            if vox['Y'] is None: vox['Y'] = val\n",
    "                        except Exception:\n",
    "                            pass\n",
    "                    if vox['X'] is None and px is not None:\n",
    "                        vx = _to_um(px, unit)\n",
    "                        if vx: vox['X'] = vx\n",
    "                    if vox['Y'] is None and py is not None:\n",
    "                        vy = _to_um(py, unit)\n",
    "                        if vy: vox['Y'] = vy\n",
    "            except Exception:\n",
    "                pass\n",
    "    except Exception:\n",
    "        pass\n",
    "    # 5) Final fallback: try ANTs (as in antsQC) if available; works for NRRD/TIFF and reads spacing header\n",
    "    try:\n",
    "        import ants  # type: ignore\n",
    "        img = ants.image_read(str(path))\n",
    "        sp = tuple(float(s) for s in img.spacing)  # (dx,dy[,dz])\n",
    "        if len(sp) >= 2:\n",
    "            if vox['X'] is None: vox['X'] = sp[0]*1.0  # dx (µm)\n",
    "            if vox['Y'] is None: vox['Y'] = sp[1]*1.0  # dy (µm)\n",
    "        if len(sp) >= 3 and vox['Z'] is None:\n",
    "            vox['Z'] = sp[2]*1.0  # dz (µm)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return vox\n",
    "\n",
    "def load_or_cache_voxels(path, alias):\n",
    "    cache = {}\n",
    "    if VOX_CACHE_PATH.exists():\n",
    "        try:\n",
    "            with open(VOX_CACHE_PATH, 'r') as f:\n",
    "                cache = json.load(f)\n",
    "        except Exception:\n",
    "            cache = {}\n",
    "    by_path = cache.get('by_path', {})\n",
    "    pkey = str(Path(path))\n",
    "    if pkey in by_path:\n",
    "        cached = by_path[pkey]\n",
    "        # If cached entry is incomplete, try to re-infer now\n",
    "        try:\n",
    "            incomplete = cached is None or any(cached.get(ax) is None for ax in ('X','Y','Z'))\n",
    "        except Exception:\n",
    "            incomplete = True\n",
    "        if not incomplete:\n",
    "            return cached\n",
    "        # Re-infer and update cache\n",
    "        vox = infer_voxels_tiff(path)\n",
    "        cache['by_path'][pkey] = vox\n",
    "        cache.setdefault('by_alias', {})[alias] = vox\n",
    "        try:\n",
    "            with open(VOX_CACHE_PATH, 'w') as f:\n",
    "                json.dump(cache, f, indent=2)\n",
    "        except Exception:\n",
    "            pass\n",
    "        return vox\n",
    "    vox = infer_voxels_tiff(path)\n",
    "    cache.setdefault('by_path', {})[pkey] = vox\n",
    "    cache.setdefault('by_alias', {})[alias] = vox\n",
    "    try:\n",
    "        with open(VOX_CACHE_PATH, 'w') as f:\n",
    "            json.dump(cache, f, indent=2)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return vox\n",
    "\n",
    "def rescale_to_match_xy(img, vox_src, vox_dst, order=1):\n",
    "    try:\n",
    "        sy = float(vox_src.get('Y')) / float(vox_dst.get('Y'))\n",
    "        sx = float(vox_src.get('X')) / float(vox_dst.get('X'))\n",
    "    except Exception:\n",
    "        return img\n",
    "    if not np.isfinite(sy) or not np.isfinite(sx):\n",
    "        return img\n",
    "    if abs(sy - 1.0) < 1e-3 and abs(sx - 1.0) < 1e-3:\n",
    "        return img\n",
    "    out_shape = (max(1, int(round(img.shape[0] * sy))), max(1, int(round(img.shape[1] * sx))))\n",
    "    return transform.resize(img, out_shape, order=order, preserve_range=True, anti_aliasing=True).astype(np.float32)    \n",
    "\n",
    "def _ensure_uint_labels(arr):\n",
    "    arr = np.asarray(arr)\n",
    "    if not np.issubdtype(arr.dtype, np.integer):\n",
    "        arr = arr.astype(np.int64)\n",
    "    return arr\n",
    "\n",
    "def _regionprops_centroids_2d(label_img):\n",
    "    tbl = measure.regionprops_table(label_img, properties=['label', 'centroid'])\n",
    "    df = pd.DataFrame(tbl).rename(columns={'centroid-0': 'cy', 'centroid-1': 'cx'})\n",
    "    df = df[df['label'] != 0].reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def _apply_tform_points_xy(tform, x, y):\n",
    "    pts = np.stack([x, y], axis=1)\n",
    "    pts_t = tform(pts)\n",
    "    return pts_t[:,0], pts_t[:,1]\n",
    "\n",
    "def diameters_um_from_array(arr, vox, axis_order=('Z','Y','X')):\n",
    "    \"\"\"Compute per-label diameters along Z/Y/X in µm from a 3D label array.\n",
    "    Expects vox like {'Z': dz, 'Y': dy, 'X': dx}.\n",
    "    \"\"\"\n",
    "    from skimage.measure import regionprops_table\n",
    "    arr = np.asarray(arr)\n",
    "    if arr.ndim != 3:\n",
    "        raise ValueError('diameters_um_from_array expects a 3D label array (Z,Y,X)')\n",
    "    props = regionprops_table(arr, properties=('label','bbox'))\n",
    "    df = pd.DataFrame(props)\n",
    "    if df.empty:\n",
    "        return pd.DataFrame(columns=['label','z_um','y_um','x_um'])\n",
    "    df = df.rename(columns={\n",
    "        'bbox-0':'zmin','bbox-1':'ymin','bbox-2':'xmin',\n",
    "        'bbox-3':'zmax','bbox-4':'ymax','bbox-5':'xmax'\n",
    "    })\n",
    "    dz = float(vox.get('Z', 1.0)); dy = float(vox.get('Y', 1.0)); dx = float(vox.get('X', 1.0))\n",
    "    df['z_um'] = (df['zmax'] - df['zmin']) * dz\n",
    "    df['y_um'] = (df['ymax'] - df['ymin']) * dy\n",
    "    df['x_um'] = (df['xmax'] - df['xmin']) * dx\n",
    "    df = df[['label','z_um','y_um','x_um']].copy()\n",
    "    df['label'] = df['label'].astype(int)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22065077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer and cache voxel sizes (µm) for func/anat[/HCR]\n",
    "VOX_CACHE_PATH = OUTDIR / 'voxel_sizes.json'\n",
    "\n",
    "# Detect from headers (fast, cached)\n",
    "detF = load_or_cache_voxels(FUNC_STACK_PATH, 'func') if FUNC_STACK_PATH else {}\n",
    "detA = load_or_cache_voxels(ANAT_STACK_PATH, 'anat') if ANAT_STACK_PATH else {}\n",
    "detH = load_or_cache_voxels(HCR_STACK_PATH,  'hcr') if 'HCR_STACK_PATH' in globals() and HCR_STACK_PATH else {}\n",
    "\n",
    "# Start from detected values\n",
    "VOX_FUNC = dict(detF or {})\n",
    "VOX_ANAT = dict(detA or {})\n",
    "VOX_HCR  = dict(detH or {}) if detH else None\n",
    "\n",
    "# Manual overrides (fill per-axis if provided)\n",
    "if isinstance(globals().get('VOX_FUNC_MANUAL', None), dict):\n",
    "    for ax in ('X','Y','Z'):\n",
    "        v = VOX_FUNC_MANUAL.get(ax)\n",
    "        if v is not None:\n",
    "            try: VOX_FUNC[ax] = float(v)\n",
    "            except Exception: VOX_FUNC[ax] = v\n",
    "if isinstance(globals().get('VOX_ANAT_MANUAL', None), dict):\n",
    "    for ax in ('X','Y','Z'):\n",
    "        v = VOX_ANAT_MANUAL.get(ax)\n",
    "        if v is not None:\n",
    "            try: VOX_ANAT[ax] = float(v)\n",
    "            except Exception: VOX_ANAT[ax] = v\n",
    "\n",
    "print('Voxel sizes (µm): func=', VOX_FUNC, 'anat=', VOX_ANAT, 'hcr=', VOX_HCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f24727",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Build a crisp functional reference per plane\n",
    "\n",
    "If your functional input is **single-plane over time**: this outputs one reference.  \n",
    "If it's **volume over time**: set `PLANE_INDEX` to the plane you want, or loop planes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3def2382",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load functional data\n",
    "func = imread(FUNC_STACK_PATH)\n",
    "print(\"Functional shape:\", func.shape)\n",
    "\n",
    "# Detect dimensionality: (T, Y, X) or (T, Z, Y, X)\n",
    "if func.ndim == 3:\n",
    "    # Single plane over time\n",
    "    T, H, W = func.shape\n",
    "    # Non-normalized time mean used for output/warping\n",
    "    ref2d_raw = func.mean(axis=0).astype(np.float32)\n",
    "    imwrite(OUTDIR/'func_ref_plane0_raw.tif', ref2d_raw.astype(np.float32))\n",
    "    # Normalized copy (for matching/visualization)\n",
    "    ref2d = norm01(ref2d_raw)\n",
    "    imwrite(OUTDIR/'func_ref_plane0.tif', (ref2d*65535).astype(np.uint16))\n",
    "    print(f\"Saved reference to {OUTDIR/'func_ref_plane0.tif'}\")\n",
    "    quickshow(ref2d, \"Functional reference (time mean, normalized for matching)\")\n",
    "else:\n",
    "    # Volume over time\n",
    "    T, Z, H, W = func.shape\n",
    "    PLANE_INDEX = 0  # EDIT: choose plane\n",
    "    plane_t = func[:, PLANE_INDEX, :, :]\n",
    "    # Non-normalized time mean for selected plane\n",
    "    ref2d_raw = plane_t.mean(axis=0).astype(np.float32)\n",
    "    imwrite(OUTDIR/f'func_ref_plane{PLANE_INDEX}_raw.tif', ref2d_raw.astype(np.float32))\n",
    "    # Normalized copy (for matching/visualization)\n",
    "    ref2d = norm01(ref2d_raw)\n",
    "    imwrite(OUTDIR/f'func_ref_plane{PLANE_INDEX}.tif', (ref2d*65535).astype(np.uint16))\n",
    "    print(f\"Saved reference to {OUTDIR/f'func_ref_plane{PLANE_INDEX}.tif'}\")\n",
    "    quickshow(ref2d, f\"Functional reference (time mean, normalized for matching, plane {PLANE_INDEX})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09947698",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Find the best matching Z in the 2P anatomy stack\n",
    "We correlate the functional reference against each anatomy slice and take the Z with the maximum NCC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182119cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "anat = imread(ANAT_STACK_PATH)\n",
    "print(\"Anatomy shape:\", anat.shape)\n",
    "\n",
    "# Optional pre-filter to enhance structure\n",
    "anat_f = np.stack([local_unsharp(norm01(s), 1.0, 0.6) for s in anat], axis=0)\n",
    "# Use normalized reference only for matching/transform estimation\n",
    "ref_match  = local_unsharp(norm01(ref2d_raw), 1.0, 0.6)\n",
    "\n",
    "# Optional: rescale functional reference to match anatomy XY before NCC\n",
    "if RESCALE_FOR_NCC:\n",
    "    try:\n",
    "        if 'VOX_FUNC' in globals() and 'VOX_ANAT' in globals() and VOX_FUNC and VOX_ANAT:\n",
    "            _sy = float(VOX_FUNC.get('Y', 1.0)) / float(VOX_ANAT.get('Y', 1.0))\n",
    "            _sx = float(VOX_FUNC.get('X', 1.0)) / float(VOX_ANAT.get('X', 1.0))\n",
    "            print(f'Rescale for NCC: sy={_sy:.4f}, sx={_sx:.4f}, ref shape {ref_match.shape}')\n",
    "            ref_match = rescale_to_match_xy(ref_match, VOX_FUNC, VOX_ANAT)\n",
    "            print(f'→ Rescaled ref shape {ref_match.shape}')\n",
    "    except Exception as _e:\n",
    "        print('Warning: voxel-based rescale skipped:', _e)\n",
    "\n",
    "best_z, scores = best_z_by_ncc(ref_match, anat_f, use_cv2=True)\n",
    "print(\"Best Z in anatomy:\", best_z)\n",
    "\n",
    "# Save scores for QA\n",
    "pd.Series(scores).to_csv(OUTDIR/'bestZ_scores.csv', index=False)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(scores); plt.axvline(best_z, linestyle='--')\n",
    "plt.xlabel('Z'); plt.ylabel('NCC score'); plt.title('Best-Z scores')\n",
    "plt.show()\n",
    "\n",
    "# Sanity check: visualize functional ref (green) vs anatomy best-Z (magenta)\n",
    "f_vis = norm01(ref2d)\n",
    "a_vis = norm01(anat[best_z])\n",
    "# Harmonize shapes for overlay — resize functional to anatomy slice shape if needed\n",
    "if f_vis.shape != a_vis.shape:\n",
    "    try:\n",
    "        f_vis = transform.resize(f_vis, a_vis.shape, order=1, mode='reflect',\n",
    "                                 preserve_range=True, anti_aliasing=True).astype(np.float32)\n",
    "    except Exception as _e:\n",
    "        # Fallback: center-crop both to common min size\n",
    "        th, tw = min(f_vis.shape[0], a_vis.shape[0]), min(f_vis.shape[1], a_vis.shape[1])\n",
    "        def _cc(img, th, tw):\n",
    "            h, w = img.shape; y0 = max(0, (h-th)//2); x0 = max(0, (w-tw)//2); return img[y0:y0+th, x0:x0+tw]\n",
    "        f_vis = _cc(f_vis, th, tw); a_vis = _cc(a_vis, th, tw)\n",
    "func_rgb = np.stack([np.zeros_like(f_vis), f_vis, np.zeros_like(f_vis)], axis=-1)\n",
    "anat_rgb = np.stack([a_vis, np.zeros_like(a_vis), a_vis], axis=-1)\n",
    "overlay = np.clip(func_rgb + anat_rgb, 0, 1)\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,3,1); plt.imshow(func_rgb); plt.title('Functional ref (green)'); plt.axis('off')\n",
    "plt.subplot(1,3,2); plt.imshow(anat_rgb); plt.title(f'Anatomy Z={best_z} (magenta)'); plt.axis('off')\n",
    "plt.subplot(1,3,3); plt.imshow(overlay); plt.title('Overlay (G + M)'); plt.axis('off')\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "quickshow(anat[best_z], f'Anatomy slice Z={best_z}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb325dd5",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Estimate in-plane transform (functional → anatomy[best‑Z])\n",
    "We try ORB+RANSAC to get a **similarity** (shift/scale/rotation) transform, and fall back to phase correlation (shift only).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compare-ref-md",
   "metadata": {},
   "source": [
    "\n",
    "## Compare functional projections (normalized vs raw)\n",
    "\n",
    "Side-by-side view to sanity-check normalization effects before overlay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare-ref-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compare normalized reference (ref2d) and non-normalized mean (ref2d_raw)\n",
    "import numpy as _np\n",
    "import matplotlib.pyplot as _plt\n",
    "_plt.figure(figsize=(10,5))\n",
    "_plt.subplot(1,2,1); _plt.imshow(ref2d, cmap='gray', vmin=0, vmax=1); _plt.title('Normalized (for matching)'); _plt.axis('off')\n",
    "vmin, vmax = _np.percentile(ref2d_raw.astype(_np.float32), (1,99))\n",
    "_plt.subplot(1,2,2); _plt.imshow(ref2d_raw, cmap='gray', vmin=vmin, vmax=vmax); _plt.title('Raw time-mean (1–99% display)'); _plt.axis('off')\n",
    "_plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4806a2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Stage 1: Similarity (rigid+scale) via ORB+RANSAC\n",
    "tform_sim = estimate_inplane_transform(ref_match, anat_f[best_z], method='similarity')\n",
    "print(\"Similarity tform:\", tform_sim.params)\n",
    "\n",
    "# Stage 2: Affine via ORB+RANSAC (optional)\n",
    "tform_aff = estimate_inplane_transform(ref_match, anat_f[best_z], method='affine')\n",
    "print(\"Affine (RANSAC) tform:\", tform_aff.params)\n",
    "\n",
    "# Stage 3: Intensity-based affine refinement (ECC) starting from the affine estimate\n",
    "tform = refine_affine_ecc(ref_match, anat_f[best_z], init_tform=tform_aff, max_iters=300, eps=1e-6, pyr_levels=3)\n",
    "print(\"Affine (ECC refined) tform:\", tform.params)\n",
    "\n",
    "# Warp the NON-normalized average into anatomy space for visual QA\n",
    "ref_warped_raw = apply_transform_2d(ref2d_raw, tform, output_shape=anat_f[best_z].shape, order=1)\n",
    "quickshow(norm01(ref_warped_raw), 'Functional (raw mean) warped → anatomy')\n",
    "quickshow(anat_f[best_z], 'Anatomy best-Z')\n",
    "\n",
    "# Overlay QA\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(anat_f[best_z], alpha=0.7)\n",
    "plt.imshow(norm01(ref_warped_raw), alpha=0.3)\n",
    "plt.title('Overlay (anatomy + warped functional)')\n",
    "plt.axis('off'); plt.show()\n",
    "\n",
    "# Save transform matrix\n",
    "np.save(OUTDIR/'func_to_anat_affine_ecc_2x3.npy', tform.params)\n",
    "print(\"Saved transform to\", OUTDIR/'func_to_anat_affine_ecc_2x3.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e285d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Interactive overlay: toggle channels like FIJI\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display\n",
    "    _HAS_WIDGETS = True\n",
    "except Exception as _e:\n",
    "    _HAS_WIDGETS = False\n",
    "    print('ipywidgets not available; skipping interactive overlay. Install ipywidgets to enable.')\n",
    "\n",
    "# Prepare normalized views (may depend on earlier cells)\n",
    "__overlay_ready = True\n",
    "try:\n",
    "    # Prefer warped functional reference if available; else compute a preview using the current transform; else fall back.\n",
    "    if 'ref_warped' in globals() and ref_warped is not None:\n",
    "        f_src = ref_warped; F_SRC_LABEL = 'warped'\n",
    "    elif 'tform' in globals():\n",
    "        mov_src = ref_match if 'ref_match' in globals() else (ref2d_raw if 'ref2d_raw' in globals() else ref2d)\n",
    "        f_src = apply_transform_2d(mov_src, tform, output_shape=anat[best_z].shape, order=1); F_SRC_LABEL = 'tform-preview'\n",
    "    else:\n",
    "        f_src = ref2d; F_SRC_LABEL = 'raw'\n",
    "    f_vis = norm01(f_src)\n",
    "    a_vis = norm01(anat[best_z])\n",
    "    # Harmonize shapes for overlay — resize functional to anatomy slice shape if needed\n",
    "    if f_vis.shape != a_vis.shape:\n",
    "        f_vis = transform.resize(f_vis, a_vis.shape, order=1, mode='reflect', preserve_range=True, anti_aliasing=True).astype(np.float32)\n",
    "except Exception as _e:\n",
    "    print('Interactive overlay prerequisites missing (ref2d/anat/best_z). Run previous cells first.)')\n",
    "    __overlay_ready = False\n",
    "\n",
    "# Define simple LUTs\n",
    "_COLORS = {\n",
    "    'green':   (0.0, 1.0, 0.0),\n",
    "    'magenta': (1.0, 0.0, 1.0),\n",
    "    'red':     (1.0, 0.0, 0.0),\n",
    "    'blue':    (0.0, 0.0, 1.0),\n",
    "    'cyan':    (0.0, 1.0, 1.0),\n",
    "    'yellow':  (1.0, 1.0, 0.0),\n",
    "    'white':   (1.0, 1.0, 1.0)\n",
    "}\n",
    "\n",
    "def _apply_color(gray01, rgb):\n",
    "    r, g, b = rgb\n",
    "    return np.stack([gray01*r, gray01*g, gray01*b], axis=-1)\n",
    "\n",
    "def _render(show_func=True, show_anat=True, func_color='green', anat_color='magenta', func_alpha=1.0, anat_alpha=1.0):\n",
    "    out = np.zeros((f_vis.shape[0], f_vis.shape[1], 3), dtype=np.float32)\n",
    "    if show_anat:\n",
    "        out += _apply_color(a_vis, _COLORS[anat_color]) * float(anat_alpha)\n",
    "    if show_func:\n",
    "        out += _apply_color(f_vis, _COLORS[func_color]) * float(func_alpha)\n",
    "    out = np.clip(out, 0, 1)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(out)\n",
    "    plt.title(f'Overlay — func[{func_color}] alpha={func_alpha:.2f}, anat[{anat_color}] alpha={anat_alpha:.2f} | func src: {F_SRC_LABEL}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "show_func_cb = widgets.Checkbox(value=True, description='Show functional')\n",
    "show_anat_cb = widgets.Checkbox(value=True, description='Show anatomy')\n",
    "func_color_dd = widgets.Dropdown(options=list(_COLORS.keys()), value='green', description='Func LUT')\n",
    "anat_color_dd = widgets.Dropdown(options=list(_COLORS.keys()), value='magenta', description='Anat LUT')\n",
    "func_alpha_sl = widgets.FloatSlider(value=1.0, min=0.0, max=1.0, step=0.05, readout_format='.2f', description='Func α')\n",
    "anat_alpha_sl = widgets.FloatSlider(value=1.0, min=0.0, max=1.0, step=0.05, readout_format='.2f', description='Anat α')\n",
    "\n",
    "if _HAS_WIDGETS and __overlay_ready:\n",
    "    ui = widgets.VBox([\n",
    "        widgets.HBox([show_func_cb, func_color_dd, func_alpha_sl]),\n",
    "        widgets.HBox([show_anat_cb, anat_color_dd, anat_alpha_sl])\n",
    "    ])\n",
    "    out = widgets.interactive_output(_render, {\n",
    "        'show_func': show_func_cb,\n",
    "        'show_anat': show_anat_cb,\n",
    "        'func_color': func_color_dd,\n",
    "        'anat_color': anat_color_dd,\n",
    "        'func_alpha': func_alpha_sl,\n",
    "        'anat_alpha': anat_alpha_sl,\n",
    "    })\n",
    "    display(ui, out)\n",
    "elif _HAS_WIDGETS and not __overlay_ready:\n",
    "    print('Interactive overlay not shown: run best-Z cell first.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mask_diameters_hdr",
   "metadata": {},
   "source": [
    "\n",
    "## 3.0) Mask diameters by axis (µm)\n",
    "Assess label diameters along Z, Y, X for functional, anatomy, and HCR masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mask_diameters_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Mask diameters (µm) for anatomy, functional, HCR (if available)\n",
    "import numpy as _np, matplotlib.pyplot as _plt\n",
    "\n",
    "def _load_labels_or_none(path):\n",
    "    if path is None:\n",
    "        return None\n",
    "    try:\n",
    "        if not os.path.exists(path):\n",
    "            return None\n",
    "        arr = _ensure_uint_labels(imread(path))\n",
    "        if arr.ndim == 3 and arr.shape[-1] in (3,4):\n",
    "            arr = arr[...,0]\n",
    "        return arr\n",
    "    except Exception as _e:\n",
    "        print('Could not load labels from', path, ':', _e)\n",
    "        return None\n",
    "\n",
    "dfs = []\n",
    "anat_labels = _load_labels_or_none(ANAT_LABELS_PATH)\n",
    "if anat_labels is not None:\n",
    "    anat_3d = anat_labels if anat_labels.ndim == 3 else anat_labels[None, ...]\n",
    "    vox_a = {\n",
    "        'Z': float(VOX_ANAT.get('Z',1.0)) if 'VOX_ANAT' in globals() and VOX_ANAT else 1.0,\n",
    "        'Y': float(VOX_ANAT.get('Y',1.0)) if 'VOX_ANAT' in globals() and VOX_ANAT else 1.0,\n",
    "        'X': float(VOX_ANAT.get('X',1.0)) if 'VOX_ANAT' in globals() and VOX_ANAT else 1.0,\n",
    "    }\n",
    "    df_anat_diam = diameters_um_from_array(anat_3d, vox_a)\n",
    "    df_anat_diam['dataset'] = 'Anatomy'\n",
    "    dfs.append(df_anat_diam)\n",
    "\n",
    "func_labels = _load_labels_or_none(FUNC_LABELS_PATH)\n",
    "if func_labels is not None:\n",
    "    func_3d = func_labels if func_labels.ndim == 3 else func_labels[None, ...]\n",
    "    vox_f = {\n",
    "        'Z': 1.0,\n",
    "        'Y': float(VOX_FUNC.get('Y',1.0)) if 'VOX_FUNC' in globals() and VOX_FUNC else 1.0,\n",
    "        'X': float(VOX_FUNC.get('X',1.0)) if 'VOX_FUNC' in globals() and VOX_FUNC else 1.0,\n",
    "    }\n",
    "    df_func_diam = diameters_um_from_array(func_3d, vox_f)\n",
    "    df_func_diam['dataset'] = 'Functional'\n",
    "    dfs.append(df_func_diam)\n",
    "\n",
    "HCR_LABELS_PATH = globals().get('HCR_LABELS_PATH', None)\n",
    "hcr_labels = _load_labels_or_none(HCR_LABELS_PATH) if HCR_LABELS_PATH is not None else None\n",
    "if hcr_labels is not None:\n",
    "    hcr_3d = hcr_labels if hcr_labels.ndim == 3 else hcr_labels[None, ...]\n",
    "    vox_h = {\n",
    "        'Z': float(VOX_HCR.get('Z',1.0)) if 'VOX_HCR' in globals() and VOX_HCR else 1.0,\n",
    "        'Y': float(VOX_HCR.get('Y',1.0)) if 'VOX_HCR' in globals() and VOX_HCR else 1.0,\n",
    "        'X': float(VOX_HCR.get('X',1.0)) if 'VOX_HCR' in globals() and VOX_HCR else 1.0,\n",
    "    }\n",
    "    df_hcr_diam = diameters_um_from_array(hcr_3d, vox_h)\n",
    "    df_hcr_diam['dataset'] = 'HCR'\n",
    "    dfs.append(df_hcr_diam)\n",
    "\n",
    "if not dfs:\n",
    "    print('No label volumes available for diameter analysis.')\n",
    "else:\n",
    "    df_all = pd.concat(dfs, ignore_index=True)\n",
    "    cats_plot = ['Anatomy','Functional','HCR']\n",
    "    present = [c for c in cats_plot if c in df_all['dataset'].unique()]\n",
    "\n",
    "    def _series_for_axis(axis_col):\n",
    "        ser = []\n",
    "        for ds in present:\n",
    "            vals = df_all.loc[df_all['dataset']==ds, axis_col].to_numpy(dtype=float)\n",
    "            ser.append(vals)\n",
    "        return ser\n",
    "\n",
    "    series_x = _series_for_axis('x_um')\n",
    "    series_y = _series_for_axis('y_um')\n",
    "    series_z = _series_for_axis('z_um')\n",
    "\n",
    "    all_vals = _np.concatenate([a for a in (series_x + series_y + series_z) if a.size]) if any(\n",
    "        (a.size for a in (series_x + series_y + series_z))) else _np.array([])\n",
    "    y_max_data = float(_np.max(all_vals)) if all_vals.size else 10.0\n",
    "    from math import ceil as _ceil\n",
    "    y_max = max(10.0, 10.0 * _ceil(y_max_data / 10.0))\n",
    "    yticks = _np.arange(0.0, y_max + 0.1, 10.0)\n",
    "\n",
    "    color_map = {'Anatomy':'#bbbbbb', 'Functional':'#88ccee', 'HCR':'#cc88ff'}\n",
    "    colors = [color_map.get(ds, '#cccccc') for ds in present]\n",
    "\n",
    "    fig, axes = _plt.subplots(1, 3, figsize=(20, 4.5), sharey=True)\n",
    "    if not hasattr(axes, '__len__'):\n",
    "        axes = [axes]\n",
    "    for ax, ser, title in zip(axes, [series_x, series_y, series_z], ['X diameter (µm)', 'Y diameter (µm)', 'Z diameter (µm)']):\n",
    "        if not any(a.size for a in ser):\n",
    "            ax.set_visible(False)\n",
    "            continue\n",
    "        parts = ax.violinplot(ser, showmeans=False, showmedians=False, showextrema=False)\n",
    "        for i, pc in enumerate(parts['bodies']):\n",
    "            pc.set_facecolor(colors[i])\n",
    "            pc.set_edgecolor('black')\n",
    "            pc.set_alpha(0.7)\n",
    "        x_offset = 0.18\n",
    "        y_offset = 0.02 * y_max\n",
    "        bbox_style = dict(facecolor='white', alpha=0.7, edgecolor='none', pad=1.0)\n",
    "        for i, vals in enumerate(ser, start=1):\n",
    "            if vals.size:\n",
    "                med = float(_np.median(vals))\n",
    "                ax.scatter([i], [med], color='crimson', zorder=3, s=26)\n",
    "                label_txt = 'median={:.2f} µm\\nn={:d}'.format(med, vals.size)\n",
    "                ax.text(i + x_offset, med + y_offset, label_txt,\n",
    "                        va='bottom', ha='left', fontsize=8, bbox=bbox_style, clip_on=False, zorder=4)\n",
    "        ax.set_title(title)\n",
    "        ax.set_xticks(range(1, len(present)+1))\n",
    "        ax.set_xticklabels(present, rotation=0)\n",
    "        ax.set_ylim(0, y_max)\n",
    "        ax.set_yticks(yticks)\n",
    "        ax.grid(axis='y', alpha=0.2)\n",
    "    fig.suptitle('Mask diameters by axis — Anatomy, Functional, HCR')\n",
    "    _plt.tight_layout()\n",
    "    _plt.show()\n",
    "\n",
    "    rows = []\n",
    "    for ds in present:\n",
    "        sub = df_all[df_all['dataset']==ds]\n",
    "        if sub.empty:\n",
    "            rows.append({'dataset': ds, 'x_median': _np.nan, 'y_median': _np.nan, 'z_median': _np.nan, 'n': 0})\n",
    "        else:\n",
    "            rows.append({\n",
    "                'dataset': ds,\n",
    "                'x_median': float(_np.median(sub['x_um'])) if len(sub['x_um']) else _np.nan,\n",
    "                'y_median': float(_np.median(sub['y_um'])) if len(sub['y_um']) else _np.nan,\n",
    "                'z_median': float(_np.median(sub['z_um'])) if len(sub['z_um']) else _np.nan,\n",
    "                'n': int(len(sub)),\n",
    "            })\n",
    "    med_table = pd.DataFrame(rows)\n",
    "    try:\n",
    "        display(med_table)\n",
    "    except Exception:\n",
    "        print(med_table.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a_dist_violin_hdr",
   "metadata": {},
   "source": [
    "\n",
    "## 3.1a) Centroid distance distribution + threshold QA\n",
    "Violin plot of functional→anatomy centroid distances (µm), with median and N.\n",
    "Use the slider to see how many cells remain under a distance threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a_dist_violin_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load or compute matches if needed\n",
    "if 'links_df' not in globals() or links_df is None or len(links_df)==0:\n",
    "    try:\n",
    "        links_df = pd.read_csv(OUTDIR/'f2a_centroid_matches.csv')\n",
    "    except Exception:\n",
    "        links_df = None\n",
    "\n",
    "# Compute links_df if still missing\n",
    "if (links_df is None or not len(links_df)):\n",
    "    try:\n",
    "        # Load labels if available\n",
    "        func_labels = None; anat_labels = None\n",
    "        if FUNC_LABELS_PATH and os.path.exists(FUNC_LABELS_PATH):\n",
    "            func_labels = _ensure_uint_labels(imread(FUNC_LABELS_PATH))\n",
    "            if func_labels.ndim == 3:\n",
    "                func_labels = func_labels[...,0]\n",
    "        if ANAT_LABELS_PATH and os.path.exists(ANAT_LABELS_PATH):\n",
    "            anat_labels = _ensure_uint_labels(imread(ANAT_LABELS_PATH))\n",
    "        if func_labels is None or anat_labels is None:\n",
    "            raise RuntimeError('Missing FUNC_LABELS_PATH or ANAT_LABELS_PATH')\n",
    "        # Ensure functional labels same size as functional reference\n",
    "        if 'ref2d' in globals() and func_labels.shape != ref2d.shape:\n",
    "            func_labels = transform.resize(func_labels, ref2d.shape, order=0, preserve_range=True, anti_aliasing=False).astype(func_labels.dtype)\n",
    "        # Anatomy slice at best_z\n",
    "        anat_labels_z = anat_labels[int(best_z)] if anat_labels.ndim==3 else anat_labels\n",
    "        # Centroids\n",
    "        fdf = _regionprops_centroids_2d(func_labels)\n",
    "        tx, ty = _apply_tform_points_xy(tform, fdf['cx'].values, fdf['cy'].values)\n",
    "        fdf['cx_t'] = tx; fdf['cy_t'] = ty\n",
    "        adf = _regionprops_centroids_2d(anat_labels_z)\n",
    "        # Match by Hungarian on Euclidean distance (pixels)\n",
    "        F = fdf[['cx_t','cy_t']].to_numpy(); A = adf[['cx','cy']].to_numpy()\n",
    "        d2 = ((F[:,None,:] - A[None,:,:])**2).sum(axis=2); D = np.sqrt(d2)\n",
    "        from scipy.optimize import linear_sum_assignment as _lsa\n",
    "        row_ind, col_ind = _lsa(D)\n",
    "        MAX_LINK_DIST_PX = 50.0\n",
    "        keep = D[row_ind, col_ind] <= MAX_LINK_DIST_PX\n",
    "        row_ind = row_ind[keep]; col_ind = col_ind[keep]\n",
    "        # Voxels for µm conversion\n",
    "        try:\n",
    "            vox_x = float(VOX_ANAT.get('X', VOX_ANAT.get(2, VOX_ANAT.get('2', 1.0))))\n",
    "            vox_y = float(VOX_ANAT.get('Y', VOX_ANAT.get(1, VOX_ANAT.get('1', 1.0))))\n",
    "        except Exception:\n",
    "            vox_x, vox_y = 1.0, 1.0\n",
    "        links = []\n",
    "        for r, c in zip(row_ind, col_ind):\n",
    "            fxp, fyp = float(F[r,0]), float(F[r,1]); axp, ayp = float(A[c,0]), float(A[c,1])\n",
    "            dist_px = float(D[r,c])\n",
    "            dx_um = (fxp - axp) * vox_x; dy_um = (fyp - ayp) * vox_y\n",
    "            dist_um = float(np.sqrt(dx_um*dx_um + dy_um*dy_um))\n",
    "            links.append({'fx_anat_px': fxp, 'fy_anat_px': fyp, 'ax_px': axp, 'ay_px': ayp, 'dist_px': dist_px, 'dist_um': dist_um})\n",
    "        import pandas as _pd\n",
    "        links_df = _pd.DataFrame(links)\n",
    "        if len(links_df):\n",
    "            links_df.to_csv(OUTDIR/'f2a_centroid_matches.csv', index=False)\n",
    "    except Exception as _e:\n",
    "        print('Could not compute matches for 3.1a:', _e)\n",
    "\n",
    "if links_df is not None and len(links_df):\n",
    "    import numpy as _np, matplotlib.pyplot as _plt\n",
    "    d = links_df['dist_um'].to_numpy().astype(float)\n",
    "    N = int(d.size); med = float(_np.median(d))\n",
    "    # Precompute background image once\n",
    "    try:\n",
    "        bg = norm01(anat[int(best_z)])\n",
    "    except Exception:\n",
    "        bg = None\n",
    "    try:\n",
    "        import ipywidgets as widgets\n",
    "        thr_max = float(_np.percentile(d, 99)) if N>0 else 10.0\n",
    "        thr_sl = widgets.FloatSlider(value=float(_np.percentile(d, 90)) if N>0 else 0.0, min=0.0, max=max(1.0, thr_max), step=0.1, description='Threshold (µm)')\n",
    "        out = widgets.Output(); count_html = widgets.HTML()\n",
    "        def _render(threshold):\n",
    "            with out:\n",
    "                out.clear_output(wait=True)\n",
    "                keep_mask = d <= float(threshold); keep = int(keep_mask.sum())\n",
    "                fig, (ax1, ax2) = _plt.subplots(1,2, figsize=(16,7), gridspec_kw={'width_ratios':[1,3]})\n",
    "                vp = ax1.violinplot(d, showmeans=False, showmedians=False, showextrema=False)\n",
    "                for pc in vp['bodies']:\n",
    "                    pc.set_facecolor('#88ccee'); pc.set_edgecolor('black'); pc.set_alpha(0.7)\n",
    "                ax1.axhline(med, color='crimson', linestyle='--', linewidth=1.5, label=f'Median {med:.2f} µm')\n",
    "                ax1.axhline(float(threshold), color='orange', linestyle=':', linewidth=1.5, label=f'Thresh {threshold:.2f} µm')\n",
    "                ax1.set_xticks([]); ax1.set_ylabel('Centroid distance (µm)'); ax1.set_title('Centroid distances (µm)'); ax1.legend(loc='lower right')\n",
    "                if bg is not None: ax2.imshow(bg, cmap='gray')\n",
    "                if keep and all(col in links_df.columns for col in ('ax_px','ay_px','fx_anat_px','fy_anat_px')):\n",
    "                    kept = links_df[keep_mask] if keep_mask.shape[0] == len(links_df) else links_df\n",
    "                    ax2.scatter(kept['ax_px'], kept['ay_px'], s=30, c='magenta', label='Anat centroids')\n",
    "                    ax2.scatter(kept['fx_anat_px'], kept['fy_anat_px'], s=30, facecolors='none', edgecolors='lime', label='Func→Anat centroids')\n",
    "                    for _, row in kept.iterrows():\n",
    "                        ax2.plot([row['ax_px'], row['fx_anat_px']], [row['ay_px'], row['fy_anat_px']], 'y-', alpha=0.5)\n",
    "                    ax2.legend(loc='lower right')\n",
    "                ax2.set_title('Kept links (≤ threshold) on anatomy'); ax2.axis('off'); _plt.tight_layout(); _plt.show()\n",
    "                count_html.value = f'<b>Keep:</b> {keep} / {N} cells (≤ {float(threshold):.2f} µm)'\n",
    "        ui = widgets.VBox([thr_sl, count_html, out]); widgets.interactive_output(_render, {'threshold': thr_sl}); display(ui); _render(thr_sl.value)\n",
    "    except Exception as _e:\n",
    "        print('ipywidgets not available; slider+dynamic overlay disabled.', _e)\n",
    "else:\n",
    "    print('No centroid matches to plot.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a_viewer_hdr",
   "metadata": {},
   "source": [
    "\n",
    "## 3.2) 3D viewer for anatomy with overlays\n",
    "Scroll Z, toggle overlays (anatomy labels, warped functional labels, and centroids).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a_viewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display\n",
    "    _HAS_W = True\n",
    "except Exception:\n",
    "    _HAS_W = False\n",
    "    print('ipywidgets not available; skipping 3D viewer.')\n",
    "\n",
    "if _HAS_W and 'anat' in globals():\n",
    "    Z = anat.shape[0] if anat.ndim == 3 else 1\n",
    "    z_sl = widgets.IntSlider(value=int(best_z) if 'best_z' in globals() else 0, min=0, max=max(0,Z-1), step=1, description='Z')\n",
    "    show_anat_lbl = widgets.Checkbox(value=True, description='Show anatomy labels')\n",
    "    show_func_lbl = widgets.Checkbox(value=os.path.exists(OUTDIR/'func_labels_in_anat_slice.tif'), description='Show func labels (warped)')\n",
    "    show_centroids = widgets.Checkbox(value=True, description='Show centroids')\n",
    "    alpha_lbl = widgets.FloatSlider(value=0.4, min=0.0, max=1.0, step=0.05, description='Label α')\n",
    "\n",
    "    # Load for viewer (lazy)\n",
    "    _anat_labels = None\n",
    "    if ANAT_LABELS_PATH and os.path.exists(ANAT_LABELS_PATH):\n",
    "        _anat_labels = _ensure_uint_labels(imread(ANAT_LABELS_PATH))\n",
    "    _func_warp = None\n",
    "    fw_path = OUTDIR/'func_labels_in_anat_slice.tif'\n",
    "    if os.path.exists(fw_path):\n",
    "        _func_warp = _ensure_uint_labels(imread(fw_path))\n",
    "\n",
    "    def _draw(z, show_al, show_fl, show_pts, alpha):\n",
    "        sl = anat[z] if anat.ndim == 3 else anat\n",
    "        plt.figure(figsize=(6,6))\n",
    "        plt.imshow(norm01(sl), cmap='gray')\n",
    "        if show_al and _anat_labels is not None:\n",
    "            if _anat_labels.ndim == 3:\n",
    "                al = _anat_labels[z]\n",
    "            else:\n",
    "                al = _anat_labels\n",
    "            plt.imshow(al, cmap='nipy_spectral', alpha=alpha, interpolation='nearest')\n",
    "        if show_fl and _func_warp is not None and z == int(best_z):\n",
    "            plt.imshow(_func_warp, cmap='viridis', alpha=alpha, interpolation='nearest')\n",
    "        if show_pts and os.path.exists(OUTDIR/'f2a_centroid_matches.csv') and z == int(best_z):\n",
    "            df = pd.read_csv(OUTDIR/'f2a_centroid_matches.csv')\n",
    "            if len(df):\n",
    "                plt.scatter(df['ax_px'], df['ay_px'], s=25, c='magenta', label='Anat c')\n",
    "                plt.scatter(df['fx_anat_px'], df['fy_anat_px'], s=25, facecolors='none', edgecolors='lime', label='Func→Anat c')\n",
    "        plt.title(f'Anatomy Z={z}')\n",
    "        plt.axis('off'); plt.show()\n",
    "\n",
    "    out = widgets.interactive_output(_draw, {\n",
    "        'z': z_sl, 'show_al': show_anat_lbl, 'show_fl': show_func_lbl, 'show_pts': show_centroids, 'alpha': alpha_lbl\n",
    "    })\n",
    "    ui = widgets.VBox([z_sl, widgets.HBox([show_anat_lbl, show_func_lbl, show_centroids, alpha_lbl])])\n",
    "    display(ui, out)\n",
    "else:\n",
    "    print('3D viewer prerequisites missing (anat, ipywidgets).')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a563d68",
   "metadata": {},
   "source": [
    "\n",
    "## 4) (Optional) Transfer ROI labels safely (nearest-neighbor)\n",
    "\n",
    "If you have a label image (e.g., Cellpose IDs), warp it with **order=0** (nearest‑neighbor) to avoid fragmentation or mixing of labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9b6910",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if LABELS_PATH and os.path.exists(LABELS_PATH):\n",
    "    labels = imread(LABELS_PATH)\n",
    "    if labels.ndim == 2:\n",
    "        labels_warp = resample_labels_nn(labels, tform, output_shape=anat.shape[1:])\n",
    "        imwrite(OUTDIR/'labels_in_anat_space.tif', labels_warp.astype(np.uint16))\n",
    "        print(\"Saved labels_in_anat_space.tif\")\n",
    "        quickshow(labels_warp>0, 'Labels (any>0) in anatomy space')\n",
    "    else:\n",
    "        print(\"LABELS_PATH is not a 2D label image; adapt code for your layout.\")\n",
    "else:\n",
    "    print(\"No LABELS_PATH provided; skipping labels transfer.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0f69e8",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Apply anatomy → HCR 3D warp (hook)\n",
    "\n",
    "Provide a function `warp3d_func(slice_img, z_index)` that applies your 3D deformation field to a 2D slice at Z.  \n",
    "This is where you plug in BigWarp/ANTs/SimpleITK. Below is a **mock** that passes data through unchanged.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1c7ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dummy_warp3d(slice_img, z_index):\n",
    "    # Replace with your BigWarp/ANTs application. This is identity.\n",
    "    return slice_img\n",
    "\n",
    "# Example usage:\n",
    "slice_in_hcr = apply_anat_to_hcr_warp_2d(ref_warped, best_z, warp3d_func=dummy_warp3d)\n",
    "quickshow(slice_in_hcr, 'Slice in HCR space (dummy)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da94f635",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Save a small JSON with parameters and results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a3df34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "meta = {\n",
    "    \"FUNC_STACK_PATH\": str(FUNC_STACK_PATH) if 'FUNC_STACK_PATH' in globals() and FUNC_STACK_PATH else None,\n",
    "    \"ANAT_STACK_PATH\": str(ANAT_STACK_PATH) if 'ANAT_STACK_PATH' in globals() and ANAT_STACK_PATH else None,\n",
    "    \"HCR_STACK_PATH\": str(HCR_STACK_PATH) if 'HCR_STACK_PATH' in globals() and HCR_STACK_PATH else None,\n",
    "    \"best_z\": int(best_z),\n",
    "    \"transform_params_2x3\": tform.params.tolist(),\n",
    "    \"ref_build_strategy\": str(REF_BUILD_STRATEGY) if 'REF_BUILD_STRATEGY' in globals() else None,\n",
    "    \"voxels\": {\"func\": VOX_FUNC, \"anat\": VOX_ANAT, \"hcr\": VOX_HCR},\n",
    "    \"voxel_cache\": str(VOX_CACHE_PATH) if 'VOX_CACHE_PATH' in globals() else None,\n",
    "    \"rng_seed\": RNG_SEED,\n",
    "}\n",
    "\n",
    "with open(OUTDIR/'run_metadata.json', 'w') as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "print(\"Wrote\", OUTDIR/'run_metadata.json')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1513e280",
   "metadata": {},
   "source": [
    "\n",
    "## Notes & next steps\n",
    "\n",
    "- If the NCC best‑Z curve is **broad** or has multiple peaks, consider matching a **slab** (±2–3 slices) instead of a single slice.\n",
    "- For in‑plane alignment, try `method='affine'` if you suspect slight shear/scale differences.\n",
    "- To register **anatomy → HCR** in Python, consider:\n",
    "  - **SimpleITK (Elastix)**: rigid→affine→B‑spline with mutual information.\n",
    "  - **ANTsPy**: SyN-based deformable registration.\n",
    "- Once you have a 3D transform, apply it to **grayscale** with linear order, to **labels** with nearest‑neighbor.\n",
    "- Compose transforms and resample once if you can (functional → anatomy → HCR → output)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "registrations",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
