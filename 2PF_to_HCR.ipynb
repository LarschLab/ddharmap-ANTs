{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1eb3fd5",
   "metadata": {},
   "source": [
    "\n",
    "# Functional → Anatomy → HCR Mapping (Zebrafish, 2P + HCR)\n",
    "\n",
    "This notebook automates a practical pipeline to map motion-corrected functional planes to the best matching **2P anatomy** Z-plane and then into **HCR/confocal** space.\n",
    "\n",
    "**Core steps**\n",
    "1. Build a *crisp* per-plane functional reference using a Suite2p-style **top‑correlated mean**.\n",
    "2. For each plane, find the **best matching Z** in the 2P anatomy stack via **normalized cross‑correlation**.\n",
    "3. Estimate an **in‑plane transform** (shift/similarity) from functional reference → anatomy[best‑Z].\n",
    "4. Apply a precomputed **3D warp** (anatomy → HCR) to place the functional plane/slab into HCR space.\n",
    "5. Transfer **ROI labels** (nearest‑neighbor) or **fluorescence images** (linear) as appropriate.\n",
    "\n",
    "> Tip: Set the voxel sizes (µm) correctly for both stacks before registration, and keep a record of transforms so you can compose and resample **once** wherever possible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a2f028",
   "metadata": {},
   "source": [
    "\n",
    "## Requirements\n",
    "\n",
    "This notebook uses common scientific Python packages:\n",
    "\n",
    "- `numpy`, `scipy`, `pandas`\n",
    "- `tifffile`\n",
    "- `scikit-image` (`skimage`)\n",
    "- `opencv-python` (optional; speeds up template matching)\n",
    "- `matplotlib` for quick QA plots\n",
    "\n",
    "If an import fails, install the package in your environment and re-run the cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a88d88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, json, math, random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tifffile import imread, imwrite\n",
    "from skimage import filters, exposure, transform, feature, measure, registration, img_as_float32\n",
    "from skimage.transform import SimilarityTransform, AffineTransform, warp\n",
    "from skimage.util import img_as_ubyte\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "# Optional OpenCV (accelerated NCC); guarded import\n",
    "try:\n",
    "    import cv2\n",
    "    HAS_CV2 = True\n",
    "except Exception:\n",
    "    HAS_CV2 = False\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"HAS_CV2:\", HAS_CV2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdfe6de",
   "metadata": {},
   "source": [
    "\n",
    "## Paths & I/O\n",
    "\n",
    "Edit these to your data. You can also point to your colleague's helper notebook (`/mnt/data/fToA_registration_jl.ipynb`) if you want to copy functions from it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79034d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- User paths (EDIT ME) ---\n",
    "FUNC_STACK_PATH = '/mnt/data/functional_stack.tif'   # motion-corrected, single plane over time OR volume over time\n",
    "ANAT_STACK_PATH = '/mnt/data/anatomy_2p_stack.tif'   # 2P anatomy (structural) stack\n",
    "HCR_STACK_PATH  = '/mnt/data/hcr_stack.tif'          # HCR/confocal stack (already cleared sample)\n",
    "OUTDIR = Path('/mnt/data/f2h_outputs'); OUTDIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Optional label image to map (e.g., Cellpose labels)\n",
    "LABELS_PATH = None   # e.g., '/mnt/data/cellpose_labels.tif' (uint16 IDs)\n",
    "\n",
    "# Voxel sizes in microns (used for metadata/logging; algorithms here work in pixels)\n",
    "VOX_FUNC = (1.0, 1.0, 1.0)   # (z, y, x) for functional\n",
    "VOX_ANAT = (1.0, 1.0, 1.0)   # (z, y, x) for anatomy\n",
    "VOX_HCR  = (1.0, 1.0, 1.0)   # (z, y, x) for HCR\n",
    "\n",
    "# Random seed for reproducibility in frame subsampling\n",
    "RNG_SEED = 42\n",
    "random.seed(RNG_SEED)\n",
    "np.random.seed(RNG_SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e11d7e2",
   "metadata": {},
   "source": [
    "\n",
    "## Utility functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000291a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def zproject_mean(stack):\n",
    "    return stack.mean(axis=0)\n",
    "\n",
    "def norm01(img):\n",
    "    img = img.astype(np.float32)\n",
    "    m, M = np.percentile(img, (1, 99))\n",
    "    if M <= m:\n",
    "        M = img.max(); m = img.min()\n",
    "    out = np.clip((img - m) / (M - m + 1e-6), 0, 1)\n",
    "    return out\n",
    "\n",
    "def local_unsharp(img, blur_sigma=1.0, amount=0.6):\n",
    "    base = ndi.gaussian_filter(img, blur_sigma)\n",
    "    return np.clip(base + amount*(img - base), 0, 1)\n",
    "\n",
    "def corrcoef_img(a, b):\n",
    "    # Pearson correlation between 2D arrays\n",
    "    a = a.astype(np.float32); b = b.astype(np.float32)\n",
    "    am = a.mean(); bm = b.mean()\n",
    "    num = ((a - am)*(b - bm)).sum()\n",
    "    den = np.sqrt(((a - am)**2).sum() * ((b - bm)**2).sum()) + 1e-8\n",
    "    return float(num / den)\n",
    "\n",
    "def top_correlated_mean(stack_t, take_k=20, pre_smooth_sigma=0.5):\n",
    "    \"\"\"Suite2p-like: build crisp reference by selecting top-K frames most correlated to a provisional mean.\"\"\"\n",
    "    T, H, W = stack_t.shape\n",
    "    # Provisional mean\n",
    "    m0 = stack_t.mean(axis=0)\n",
    "    # Optional pre-smoothing to reduce shot noise\n",
    "    if pre_smooth_sigma and pre_smooth_sigma > 0:\n",
    "        m0s = ndi.gaussian_filter(m0, pre_smooth_sigma)\n",
    "    else:\n",
    "        m0s = m0\n",
    "    # Correlate each frame with provisional mean\n",
    "    corrs = np.empty(T, dtype=np.float32)\n",
    "    for i in range(T):\n",
    "        fi = stack_t[i]\n",
    "        if pre_smooth_sigma and pre_smooth_sigma > 0:\n",
    "            fi = ndi.gaussian_filter(fi, pre_smooth_sigma)\n",
    "        corrs[i] = corrcoef_img(fi, m0s)\n",
    "    # Take top-K\n",
    "    k = min(take_k, T)\n",
    "    idx = np.argsort(corrs)[-k:]\n",
    "    ref = stack_t[idx].mean(axis=0)\n",
    "    return ref, idx, corrs\n",
    "\n",
    "def best_z_by_ncc(template, anat_stack, use_cv2=True):\n",
    "    \"\"\"Return best Z index and NCC scores over Z for a 2D template vs 3D stack.\"\"\"\n",
    "    template = norm01(template)\n",
    "    H, W = template.shape\n",
    "    scores = []\n",
    "    if use_cv2 and HAS_CV2:\n",
    "        templ = (template*255).astype(np.uint8)\n",
    "        for z in range(anat_stack.shape[0]):\n",
    "            sl = norm01(anat_stack[z])\n",
    "            sl8 = (sl*255).astype(np.uint8)\n",
    "            res = cv2.matchTemplate(sl8, templ, cv2.TM_CCORR_NORMED)\n",
    "            # Whole-image match: template same size; if not, pad template or crop; here we assume same FOV/size\n",
    "            if res.size == 1:\n",
    "                s = float(res.ravel()[0])\n",
    "            else:\n",
    "                s = float(res.max())\n",
    "            scores.append(s)\n",
    "    else:\n",
    "        # fallback: simple correlation on same-size images\n",
    "        for z in range(anat_stack.shape[0]):\n",
    "            sl = norm01(anat_stack[z])\n",
    "            s = corrcoef_img(template, sl)\n",
    "            scores.append(s)\n",
    "    scores = np.asarray(scores, dtype=np.float32)\n",
    "    best_z = int(np.argmax(scores))\n",
    "    return best_z, scores\n",
    "\n",
    "def estimate_inplane_transform(mov, ref, method='similarity'):\n",
    "    \"\"\"Estimate 2D transform from moving image (mov) to reference (ref).\n",
    "    Tries ORB+RANSAC; falls back to phase cross-correlation (shift only).\"\"\"\n",
    "    m = norm01(mov); r = norm01(ref)\n",
    "    # ORB keypoints\n",
    "    try:\n",
    "        detector = feature.ORB(n_keypoints=2000, fast_threshold=0.05)\n",
    "        detector.detect_and_extract(img_as_float32(m))\n",
    "        kp1 = detector.keypoints; d1 = detector.descriptors\n",
    "        detector.detect_and_extract(img_as_float32(r))\n",
    "        kp2 = detector.keypoints; d2 = detector.descriptors\n",
    "        if len(kp1) >= 10 and len(kp2) >= 10 and d1 is not None and d2 is not None:\n",
    "            matches12 = feature.match_descriptors(d1, d2, cross_check=True, max_ratio=0.8)\n",
    "            src = kp1[matches12[:, 0]][:, ::-1]  # (x,y)\n",
    "            dst = kp2[matches12[:, 1]][:, ::-1]\n",
    "            if method == 'similarity':\n",
    "                model, inliers = measure.ransac((src, dst), SimilarityTransform,\n",
    "                                                min_samples=3, residual_threshold=2.0, max_trials=2000)\n",
    "            else:\n",
    "                model, inliers = measure.ransac((src, dst), AffineTransform,\n",
    "                                                min_samples=3, residual_threshold=2.0, max_trials=2000)\n",
    "            if model is not None:\n",
    "                return model\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    # Fallback: phase correlation for shift\n",
    "    shift, _, _ = registration.phase_cross_correlation(r, m, upsample_factor=10)\n",
    "    tform = SimilarityTransform(translation=(shift[1], shift[0]))\n",
    "    return tform\n",
    "\n",
    "def apply_transform_2d(img, tform, output_shape=None, order=1, preserve_range=True):\n",
    "    if output_shape is None:\n",
    "        output_shape = img.shape\n",
    "    warped = warp(img, inverse_map=tform.inverse, output_shape=output_shape, order=order,\n",
    "                  preserve_range=preserve_range, mode='constant', cval=0.0, clip=True)\n",
    "    return warped\n",
    "\n",
    "def resample_labels_nn(img, tform, output_shape=None):\n",
    "    # nearest-neighbor for label images\n",
    "    return apply_transform_2d(img, tform, output_shape=output_shape, order=0, preserve_range=True)\n",
    "\n",
    "def apply_anat_to_hcr_warp_2d(slice_img, z_index, warp3d_func):\n",
    "    \"\"\"Hook to apply a 3D warp (anatomy→HCR) to a 2D slice.\n",
    "    `warp3d_func` should accept (z,y,x) indices or coordinates and return warped image in HCR coords.\n",
    "    For now this is a placeholder you can implement with your BigWarp/ANTs output.\n",
    "    \"\"\"\n",
    "    return warp3d_func(slice_img, z_index)\n",
    "\n",
    "def quickshow(img, title='', vmin=None, vmax=None):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(img, vmin=vmin, vmax=vmax)\n",
    "    plt.title(title); plt.axis('off'); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f24727",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Build a crisp functional reference per plane\n",
    "\n",
    "If your functional input is **single-plane over time**: this outputs one reference.  \n",
    "If it's **volume over time**: set `PLANE_INDEX` to the plane you want, or loop planes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3def2382",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load functional data\n",
    "func = imread(FUNC_STACK_PATH)\n",
    "print(\"Functional shape:\", func.shape)\n",
    "\n",
    "# Detect dimensionality: (T, Y, X) or (T, Z, Y, X)\n",
    "if func.ndim == 3:\n",
    "    # Single plane over time\n",
    "    T, H, W = func.shape\n",
    "    ref2d, kept_idx, corrs = top_correlated_mean(func, take_k=min(20, T), pre_smooth_sigma=0.5)\n",
    "    ref2d = norm01(ref2d)\n",
    "    imwrite(OUTDIR/'func_ref_plane0.tif', (ref2d*65535).astype(np.uint16))\n",
    "    print(f\"Saved reference to {OUTDIR/'func_ref_plane0.tif'}\")\n",
    "    quickshow(ref2d, \"Functional reference (plane 0)\")\n",
    "else:\n",
    "    # Volume over time\n",
    "    T, Z, H, W = func.shape\n",
    "    PLANE_INDEX = 0  # EDIT: choose plane\n",
    "    plane_t = func[:, PLANE_INDEX, :, :]\n",
    "    ref2d, kept_idx, corrs = top_correlated_mean(plane_t, take_k=min(20, T), pre_smooth_sigma=0.5)\n",
    "    ref2d = norm01(ref2d)\n",
    "    imwrite(OUTDIR/f'func_ref_plane{PLANE_INDEX}.tif', (ref2d*65535).astype(np.uint16))\n",
    "    print(f\"Saved reference to {OUTDIR/f'func_ref_plane{PLANE_INDEX}.tif'}\")\n",
    "    quickshow(ref2d, f\"Functional reference (plane {PLANE_INDEX})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09947698",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Find the best matching Z in the 2P anatomy stack\n",
    "We correlate the functional reference against each anatomy slice and take the Z with the maximum NCC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182119cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "anat = imread(ANAT_STACK_PATH)\n",
    "print(\"Anatomy shape:\", anat.shape)\n",
    "\n",
    "# Optional pre-filter to enhance structure\n",
    "anat_f = np.stack([local_unsharp(norm01(s), 1.0, 0.6) for s in anat], axis=0)\n",
    "ref_f  = local_unsharp(norm01(ref2d), 1.0, 0.6)\n",
    "\n",
    "best_z, scores = best_z_by_ncc(ref_f, anat_f, use_cv2=True)\n",
    "print(\"Best Z in anatomy:\", best_z)\n",
    "\n",
    "# Save scores for QA\n",
    "pd.Series(scores).to_csv(OUTDIR/'bestZ_scores.csv', index=False)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(scores); plt.axvline(best_z, linestyle='--')\n",
    "plt.xlabel('Z'); plt.ylabel('NCC score'); plt.title('Best-Z scores')\n",
    "plt.show()\n",
    "\n",
    "quickshow(anat[best_z], f'Anatomy slice Z={best_z}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb325dd5",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Estimate in-plane transform (functional → anatomy[best‑Z])\n",
    "We try ORB+RANSAC to get a **similarity** (shift/scale/rotation) transform, and fall back to phase correlation (shift only).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4806a2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tform = estimate_inplane_transform(ref_f, anat_f[best_z], method='similarity')\n",
    "print(\"Estimated transform:\n",
    "\", tform.params)\n",
    "\n",
    "# Warp the functional reference into anatomy space for visual QA\n",
    "ref_warped = apply_transform_2d(ref_f, tform, output_shape=anat_f[best_z].shape, order=1)\n",
    "quickshow(ref_warped, 'Functional ref warped → anatomy')\n",
    "quickshow(anat_f[best_z], 'Anatomy best-Z')\n",
    "\n",
    "# Overlay QA\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(anat_f[best_z], alpha=0.7)\n",
    "plt.imshow(ref_warped, alpha=0.3)\n",
    "plt.title('Overlay (anatomy + warped functional)')\n",
    "plt.axis('off'); plt.show()\n",
    "\n",
    "# Save transform matrix\n",
    "np.save(OUTDIR/'func_to_anat_similarity_2x3.npy', tform.params)\n",
    "print(\"Saved transform to\", OUTDIR/'func_to_anat_similarity_2x3.npy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a563d68",
   "metadata": {},
   "source": [
    "\n",
    "## 4) (Optional) Transfer ROI labels safely (nearest-neighbor)\n",
    "\n",
    "If you have a label image (e.g., Cellpose IDs), warp it with **order=0** (nearest‑neighbor) to avoid fragmentation or mixing of labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9b6910",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if LABELS_PATH and os.path.exists(LABELS_PATH):\n",
    "    labels = imread(LABELS_PATH)\n",
    "    if labels.ndim == 2:\n",
    "        labels_warp = resample_labels_nn(labels, tform, output_shape=anat.shape[1:])\n",
    "        imwrite(OUTDIR/'labels_in_anat_space.tif', labels_warp.astype(np.uint16))\n",
    "        print(\"Saved labels_in_anat_space.tif\")\n",
    "        quickshow(labels_warp>0, 'Labels (any>0) in anatomy space')\n",
    "    else:\n",
    "        print(\"LABELS_PATH is not a 2D label image; adapt code for your layout.\")\n",
    "else:\n",
    "    print(\"No LABELS_PATH provided; skipping labels transfer.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0f69e8",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Apply anatomy → HCR 3D warp (hook)\n",
    "\n",
    "Provide a function `warp3d_func(slice_img, z_index)` that applies your 3D deformation field to a 2D slice at Z.  \n",
    "This is where you plug in BigWarp/ANTs/SimpleITK. Below is a **mock** that passes data through unchanged.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1c7ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dummy_warp3d(slice_img, z_index):\n",
    "    # Replace with your BigWarp/ANTs application. This is identity.\n",
    "    return slice_img\n",
    "\n",
    "# Example usage:\n",
    "slice_in_hcr = apply_anat_to_hcr_warp_2d(ref_warped, best_z, warp3d_func=dummy_warp3d)\n",
    "quickshow(slice_in_hcr, 'Slice in HCR space (dummy)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da94f635",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Save a small JSON with parameters and results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a3df34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "meta = {\n",
    "    \"FUNC_STACK_PATH\": FUNC_STACK_PATH,\n",
    "    \"ANAT_STACK_PATH\": ANAT_STACK_PATH,\n",
    "    \"HCR_STACK_PATH\": HCR_STACK_PATH,\n",
    "    \"best_z\": int(best_z),\n",
    "    \"transform_params_2x3\": tform.params.tolist(),\n",
    "    \"voxels\": {\"func\": VOX_FUNC, \"anat\": VOX_ANAT, \"hcr\": VOX_HCR},\n",
    "    \"rng_seed\": RNG_SEED,\n",
    "}\n",
    "\n",
    "with open(OUTDIR/'run_metadata.json', 'w') as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "print(\"Wrote\", OUTDIR/'run_metadata.json')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1513e280",
   "metadata": {},
   "source": [
    "\n",
    "## Notes & next steps\n",
    "\n",
    "- If the NCC best‑Z curve is **broad** or has multiple peaks, consider matching a **slab** (±2–3 slices) instead of a single slice.\n",
    "- For in‑plane alignment, try `method='affine'` if you suspect slight shear/scale differences.\n",
    "- To register **anatomy → HCR** in Python, consider:\n",
    "  - **SimpleITK (Elastix)**: rigid→affine→B‑spline with mutual information.\n",
    "  - **ANTsPy**: SyN-based deformable registration.\n",
    "- Once you have a 3D transform, apply it to **grayscale** with linear order, to **labels** with nearest‑neighbor.\n",
    "- Compose transforms and resample once if you can (functional → anatomy → HCR → output)."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
