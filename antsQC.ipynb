{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bceb0021",
   "metadata": {},
   "source": [
    "\n",
    "# ANTs × Cellpose Registration QC — Centroid Distances in µm\n",
    "\n",
    "**Created:** 2025-10-15 12:22\n",
    "\n",
    "This notebook computes distances (in µm) between **cort-positive cell centroids** segmented by Cellpose in two modalities:\n",
    "- **Confocal** (panneuronal GC + cort HCR in red) — *moving image* (registered to 2P)\n",
    "- **2P** (panneuronal GC + cort::mCherry) — *fixed image*\n",
    "\n",
    "The pipeline:\n",
    "1. Load Cellpose `*_seg.npy` outputs and extract labeled masks.\n",
    "2. Compute object centroids.\n",
    "3. Convert pixel indices to physical units using voxel spacings (µm).\n",
    "4. Apply the **confocal → 2P** ANTs transform to confocal centroids.\n",
    "5. Match cells (nearest neighbor or Hungarian) and compute distances in µm.\n",
    "6. Summaries and basic plots; optional gating to reject outliers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93951456",
   "metadata": {},
   "source": [
    "\n",
    "## Requirements\n",
    "\n",
    "- `numpy`, `pandas`, `scikit-image`, `scipy`, `matplotlib`\n",
    "- `ants` (ANTsPy) **optional but recommended** for applying transforms inside Python.\n",
    "  - If `ants` is not available, the notebook will export centroids to CSV and you can run\n",
    "    `antsApplyTransformsToPoints` on the command line, then re-import the transformed CSV.\n",
    "\n",
    "> Tip: For 3D Cellpose, pass correct anisotropy during segmentation to reduce z-bias.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4308c54",
   "metadata": {},
   "source": [
    "## 0) User inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7eb3f020",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Paths to Cellpose outputs ---\n",
    "CONF_SEG_NPY = \"/Users/ddharmap/dataProcessing/2p_HCR/data/L427_f02/L427_f02_round1_channel2_cort_gauss_seg_20251006.npy\"   # path to confocal *_seg.npy\n",
    "TWOP_SEG_NPY = \"/Users/ddharmap/dataProcessing/2p_HCR/data/L427_f02/L427_f02_anatomy_2P_cort_seg_anis1.npy\"       # path to 2P *_seg.npy\n",
    "\n",
    "# --- ANTs transform files (moving=confocal -> fixed=2P) ---\n",
    "# include the non-linear warp BEFORE the affine in the list\n",
    "ANTs_TRANSFORMS = [\n",
    "    \"/Volumes/jlarsch/default/D2c/07_Data/Matilde/Microscopy/L427_f02/02_reg/01_r1-2p/transMatrices/L427_f02_round1_GCaMP_to_ref1Warp.nii.gz\",          # example SyN warp\n",
    "    \"/Volumes/jlarsch/default/D2c/07_Data/Matilde/Microscopy/L427_f02/02_reg/01_r1-2p/transMatrices/L427_f02_round1_GCaMP_to_ref0GenericAffine.mat\"     # example affine\n",
    "]\n",
    "\n",
    "# --- Voxel spacings in microns ---\n",
    "# Fill these from your image metadata\n",
    "# 3D stacks: dz, dy, dx; 2D stacks: dy, dx\n",
    "VOX_CONF = {\"dz\": 1.0, \"dy\": 0.2075665, \"dx\": 0.2075665}  # example for confocal\n",
    "VOX_2P   = {\"dz\": 2.0, \"dy\": 0.6506220, \"dx\": 0.6506220}  # example for 2P\n",
    "\n",
    "# --- Matching parameters ---\n",
    "MATCH_METHOD = \"nn\"    # \"nn\" for nearest neighbor, \"hungarian\" for 1–1 global assignment\n",
    "MAX_DISTANCE_UM = 5.0 # gate for valid matches (~1 soma diameter is a good start)\n",
    "RANDOM_SEED = 42\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd460ef",
   "metadata": {},
   "source": [
    "## 1) Imports and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3c67b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, sys, json, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.measure import regionprops_table\n",
    "from scipy.spatial import cKDTree\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, IntSlider, Dropdown\n",
    "\n",
    "# Try to import ANTsPy\n",
    "try:\n",
    "    import ants\n",
    "    HAVE_ANTSPY = True\n",
    "except Exception as e:\n",
    "    HAVE_ANTSPY = False\n",
    "    print(\"ANTsPy not found; will enable CSV export/import route for transforms.\\n\", e)\n",
    "\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "\n",
    "def fs_info(path: str) -> dict:\n",
    "    \"\"\"Lightweight filesystem info.\"\"\"\n",
    "    exists = os.path.exists(path)\n",
    "    size_b = os.path.getsize(path) if exists else None\n",
    "    mtime  = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(os.path.getmtime(path))) if exists else None\n",
    "    return {\"exists\": exists, \"size_bytes\": size_b, \"size_MB\": (size_b/1e6 if size_b else None), \"modified\": mtime}\n",
    "\n",
    "def physical_extent_um(mask: np.ndarray, vox: dict) -> tuple:\n",
    "    \"\"\"Return (Z_um, Y_um, X_um) or (Y_um, X_um) physical field-of-view from mask shape and voxel sizes.\"\"\"\n",
    "    if mask.ndim == 3:\n",
    "        Z, Y, X = mask.shape\n",
    "        return (Z * vox[\"dz\"], Y * vox[\"dy\"], X * vox[\"dx\"])\n",
    "    else:\n",
    "        Y, X = mask.shape\n",
    "        return (Y * vox[\"dy\"], X * vox[\"dx\"])\n",
    "\n",
    "def summarize_dataset(name: str, path: str, masks: np.ndarray, vox: dict) -> dict:\n",
    "    \"\"\"One-row summary for a dataset (used in the table view).\"\"\"\n",
    "    base = os.path.basename(path)\n",
    "    fs = fs_info(path)\n",
    "    uniq = np.unique(masks)\n",
    "    n_cells = int(uniq.size - (1 if uniq.size and uniq[0] == 0 else 0))\n",
    "    fov = physical_extent_um(masks, vox)\n",
    "    row = {\n",
    "        \"dataset\": name,\n",
    "        \"file\": base,\n",
    "        \"path\": path,\n",
    "        \"exists\": fs[\"exists\"],\n",
    "        \"size_MB\": round(fs[\"size_MB\"], 3) if fs[\"size_MB\"] else None,\n",
    "        \"modified\": fs[\"modified\"],\n",
    "        \"shape\": tuple(masks.shape),\n",
    "        \"ndim\": masks.ndim,\n",
    "        \"dtype\": str(masks.dtype),\n",
    "        \"min_label\": int(masks.min()),\n",
    "        \"max_label\": int(masks.max()),\n",
    "        \"n_cells\": n_cells,\n",
    "        \"voxel_um\": (vox[\"dz\"], vox[\"dy\"], vox[\"dx\"]) if masks.ndim == 3 else (vox[\"dy\"], vox[\"dx\"]),\n",
    "        \"FOV_um\": tuple(round(v, 3) for v in fov),\n",
    "        \"n_voxels\": int(masks.size),\n",
    "        \"anisotropy_z_over_y\": (vox[\"dz\"]/vox[\"dy\"]) if masks.ndim == 3 else None,\n",
    "    }\n",
    "    return row\n",
    "\n",
    "def load_cellpose_masks(seg_path: str) -> np.ndarray:\n",
    "    \"\"\"Robustly load Cellpose *_seg.npy (dict) or a raw label array (.npy/.npz).\n",
    "    Returns a labeled mask ndarray (2D or 3D).\n",
    "    \"\"\"\n",
    "    if not os.path.exists(seg_path):\n",
    "        raise FileNotFoundError(f\"File not found: {seg_path}\")\n",
    "\n",
    "    try:\n",
    "        obj = np.load(seg_path, allow_pickle=True)\n",
    "    except Exception as e:\n",
    "        raise OSError(f\"Failed to load {seg_path}. If this is on a network/cloud drive, \"\n",
    "                      f\"copy it locally and retry. Original error: {e}\")\n",
    "\n",
    "    # .npz container?\n",
    "    if isinstance(obj, np.lib.npyio.NpzFile):\n",
    "        if 'masks' in obj.files:\n",
    "            return obj['masks']\n",
    "        raise KeyError(f\"{seg_path} is .npz but has no 'masks'. Keys: {obj.files}\")\n",
    "\n",
    "    # Cellpose *_seg.npy is a pickled dict inside an .npy\n",
    "    if hasattr(obj, \"item\"):\n",
    "        try:\n",
    "            dat = obj.item()\n",
    "        except Exception as e:\n",
    "            raise OSError(f\"{seg_path} appears corrupted (cannot unpickle dict). {e}\")\n",
    "        masks = dat.get('masks', None)\n",
    "        if masks is None:\n",
    "            raise KeyError(f\"'masks' not found in {seg_path}. Keys: {list(dat.keys())}\")\n",
    "        return masks\n",
    "\n",
    "    # raw array case\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return obj\n",
    "\n",
    "    raise TypeError(f\"Unexpected content in {seg_path}: {type(obj)}\")\n",
    "\n",
    "def mask_summary(mask: np.ndarray, name: str = \"\") -> dict:\n",
    "    \"\"\"Return a small dict summarizing a labeled mask.\"\"\"\n",
    "    # unique() can be heavy for huge volumes; use it here for truth, but you can swap to mask.max() if needed\n",
    "    uniq = np.unique(mask)\n",
    "    n_cells = int(uniq.size - (1 if uniq.size and uniq[0] == 0 else 0))\n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"shape\": tuple(mask.shape),\n",
    "        \"ndim\": mask.ndim,\n",
    "        \"dtype\": str(mask.dtype),\n",
    "        \"min\": int(mask.min()),\n",
    "        \"max\": int(mask.max()),\n",
    "        \"n_cells\": n_cells,\n",
    "    }\n",
    "\n",
    "def safe_slice(arr: np.ndarray, z: int) -> np.ndarray:\n",
    "    \"\"\"Return arr[z] for 3D, or arr for 2D, with z safely clamped.\"\"\"\n",
    "    if arr.ndim == 2:\n",
    "        return arr\n",
    "    z = int(np.clip(z, 0, arr.shape[0] - 1))\n",
    "    return arr[z]\n",
    "\n",
    "\n",
    "def compute_centroids(mask):\n",
    "    \"\"\"Return DataFrame of labels and centroids from a labeled mask (2D or 3D).\"\"\"\n",
    "    props = regionprops_table(mask, properties=(\"label\", \"centroid\"))\n",
    "    df = pd.DataFrame(props)\n",
    "    # Ensure consistent column names: z,y,x for 3D; y,x for 2D\n",
    "    if mask.ndim == 3:\n",
    "        df = df.rename(columns={\"centroid-0\":\"z\", \"centroid-1\":\"y\", \"centroid-2\":\"x\"})\n",
    "    else:\n",
    "        df = df.rename(columns={\"centroid-0\":\"y\", \"centroid-1\":\"x\"})\n",
    "    return df\n",
    "\n",
    "def idx_to_um(df_centroids, vox):\n",
    "    \"\"\"Convert centroid indices to microns using spacing dict vox.\"\"\"\n",
    "    if \"z\" in df_centroids.columns:\n",
    "        arr = df_centroids[[\"z\",\"y\",\"x\"]].to_numpy(dtype=float)\n",
    "        arr[:,0] *= vox[\"dz\"]\n",
    "        arr[:,1] *= vox[\"dy\"]\n",
    "        arr[:,2] *= vox[\"dx\"]\n",
    "        return arr\n",
    "    else:\n",
    "        arr = df_centroids[[\"y\",\"x\"]].to_numpy(dtype=float)\n",
    "        arr[:,0] *= vox[\"dy\"]\n",
    "        arr[:,1] *= vox[\"dx\"]\n",
    "        return arr\n",
    "\n",
    "def um_to_idx_df(points_um, vox, is3d):\n",
    "    \"\"\"Convert points in µm to MOVING image index units with columns x,y,(z).\"\"\"\n",
    "    if is3d:\n",
    "        return pd.DataFrame({\n",
    "            \"x\": points_um[:,2] / vox[\"dx\"],\n",
    "            \"y\": points_um[:,1] / vox[\"dy\"],\n",
    "            \"z\": points_um[:,0] / vox[\"dz\"],\n",
    "        })[[\"x\",\"y\",\"z\"]]\n",
    "    else:\n",
    "        return pd.DataFrame({\n",
    "            \"x\": points_um[:,1] / vox[\"dx\"],\n",
    "            \"y\": points_um[:,0] / vox[\"dy\"],\n",
    "        })[[\"x\",\"y\"]]\n",
    "\n",
    "def idx_df_to_um(df_idx, vox, is3d):\n",
    "    \"\"\"Convert FIXED image index-units DataFrame (x,y,(z)) to µm ndarray (ordered as y/x -> µm & z first for 3D).\"\"\"\n",
    "    if is3d:\n",
    "        x = df_idx[\"x\"].to_numpy(); y = df_idx[\"y\"].to_numpy(); z = df_idx[\"z\"].to_numpy()\n",
    "        return np.c_[ z * vox[\"dz\"],  y * vox[\"dy\"],  x * vox[\"dx\"] ]  # returns [µm_z, µm_y, µm_x]\n",
    "    else:\n",
    "        x = df_idx[\"x\"].to_numpy(); y = df_idx[\"y\"].to_numpy()\n",
    "        return np.c_[ y * vox[\"dy\"],  x * vox[\"dx\"] ]  # returns [µm_y, µm_x]\n",
    "\n",
    "def apply_ants_transform_to_points(conf_pts_um, is3d, ants_transforms, vox_conf, vox_2p):\n",
    "    \"\"\"Apply confocal->2P transforms to confocal points in µm. Return points in 2P µm.\"\"\"\n",
    "    if not HAVE_ANTSPY:\n",
    "        raise RuntimeError(\"ANTsPy not available.\")\n",
    "    moving_idx = um_to_idx_df(conf_pts_um, vox_conf, is3d)\n",
    "    # antspyx signature: apply_transforms_to_points(dim, points, transformlist, whichtoinvert=None)\n",
    "    fixed_idx = ants.apply_transforms_to_points(3 if is3d else 2, moving_idx, ants_transforms)\n",
    "    fixed_um = idx_df_to_um(fixed_idx, vox_2p, is3d)\n",
    "    return fixed_um\n",
    "\n",
    "def nearest_neighbor_match(A_um, B_um):\n",
    "    \"\"\"For each row in A, find nearest neighbor in B. Returns distances and indices.\"\"\"\n",
    "    tree = cKDTree(B_um)\n",
    "    dists, nn = tree.query(A_um, k=1)\n",
    "    return dists, nn\n",
    "\n",
    "def hungarian_match(A_um, B_um, max_cost=np.inf):\n",
    "    \"\"\"1–1 assignment using Hungarian algorithm with optional max_cost gate.\"\"\"\n",
    "    # Compute cost matrix\n",
    "    # Beware of large N: O(N^2) memory\n",
    "    from scipy.spatial.distance import cdist\n",
    "    C = cdist(A_um, B_um)\n",
    "    if np.isfinite(max_cost):\n",
    "        C = np.where(C > max_cost, max_cost * 10.0, C)  # penalize invalid matches\n",
    "    row_ind, col_ind = linear_sum_assignment(C)\n",
    "    dists = C[row_ind, col_ind]\n",
    "    return dists, col_ind, row_ind\n",
    "\n",
    "def summarize_distances(dists, valid_mask):\n",
    "    if valid_mask.any():\n",
    "        return {\n",
    "            \"N_total\": int(dists.size),\n",
    "            \"N_within_gate\": int(valid_mask.sum()),\n",
    "            \"frac_within_gate\": float(valid_mask.mean()),\n",
    "            \"median_um\": float(np.median(dists[valid_mask])),\n",
    "            \"p90_um\": float(np.percentile(dists[valid_mask], 90)),\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"N_total\": int(dists.size),\n",
    "            \"N_within_gate\": 0,\n",
    "            \"frac_within_gate\": 0.0,\n",
    "            \"median_um\": np.nan,\n",
    "            \"p90_um\": np.nan,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c5187d",
   "metadata": {},
   "source": [
    "## 3) Inspect datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "718b27ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "The '.style' accessor requires jinja2",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[32m/var/folders/qg/mcw76_dj3gq7p4vz0sd2w_hh0000gn/T/ipykernel_1329/418813557.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     22\u001b[39m ]\n\u001b[32m     23\u001b[39m df_inputs = df_inputs[cols]\n\u001b[32m     24\u001b[39m \n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# display + (optional) save\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m display(df_inputs.style.format({\u001b[33m\"size_MB\"\u001b[39m: \u001b[33m\"{:.3f}\"\u001b[39m}))\n\u001b[32m     27\u001b[39m df_inputs.to_csv(\u001b[33m\"input_datasets_overview.csv\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     28\u001b[39m print(\u001b[33m\"Saved table to input_datasets_overview.csv\"\u001b[39m)\n",
      "\u001b[32m~/miniforge3/envs/registrations/lib/python3.11/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   6317\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m name \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m self._accessors\n\u001b[32m   6318\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m self._info_axis._can_hold_identifiers_and_holds_name(name)\n\u001b[32m   6319\u001b[39m         ):\n\u001b[32m   6320\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self[name]\n\u001b[32m-> \u001b[39m\u001b[32m6321\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m object.__getattribute__(self, name)\n",
      "\u001b[32m~/miniforge3/envs/registrations/lib/python3.11/site-packages/pandas/core/frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1445\u001b[39m         \"\"\"\n\u001b[32m   1446\u001b[39m         \u001b[38;5;66;03m# Raise AttributeError so that inspect works even if jinja2 is not installed.\u001b[39;00m\n\u001b[32m   1447\u001b[39m         has_jinja2 = import_optional_dependency(\u001b[33m\"jinja2\"\u001b[39m, errors=\u001b[33m\"ignore\"\u001b[39m)\n\u001b[32m   1448\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m has_jinja2:\n\u001b[32m-> \u001b[39m\u001b[32m1449\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m AttributeError(\u001b[33m\"The '.style' accessor requires jinja2\"\u001b[39m)\n\u001b[32m   1450\u001b[39m \n\u001b[32m   1451\u001b[39m         \u001b[38;5;28;01mfrom\u001b[39;00m pandas.io.formats.style \u001b[38;5;28;01mimport\u001b[39;00m Styler\n\u001b[32m   1452\u001b[39m \n",
      "\u001b[31mAttributeError\u001b[39m: The '.style' accessor requires jinja2"
     ]
    }
   ],
   "source": [
    "# ==== Table-format oversight of input datasets ====\n",
    "# assumes:\n",
    "#   - masks_conf, masks_2p already loaded\n",
    "#   - CONF_SEG_NPY, TWOP_SEG_NPY, VOX_CONF, VOX_2P already defined\n",
    "\n",
    "\n",
    "masks_conf = load_cellpose_masks(CONF_SEG_NPY)\n",
    "masks_2p   = load_cellpose_masks(TWOP_SEG_NPY)\n",
    "\n",
    "rows = [\n",
    "    summarize_dataset(\"Confocal (HCR)\", CONF_SEG_NPY, masks_conf, VOX_CONF),\n",
    "    summarize_dataset(\"2P (mCherry)\",   TWOP_SEG_NPY, masks_2p,   VOX_2P),\n",
    "]\n",
    "\n",
    "df_inputs = pd.DataFrame(rows)\n",
    "\n",
    "# choose a readable column order\n",
    "cols = [\n",
    "    \"dataset\",\"file\",\"exists\",\"size_MB\",\"modified\",\n",
    "    \"shape\",\"ndim\",\"dtype\",\"min_label\",\"max_label\",\"n_cells\",\n",
    "    \"voxel_um\",\"FOV_um\",\"n_voxels\",\"anisotropy_z_over_y\",\"path\"\n",
    "]\n",
    "df_inputs = df_inputs[cols]\n",
    "\n",
    "# display + (optional) save\n",
    "display(df_inputs.style.format({\"size_MB\": \"{:.3f}\"}))\n",
    "df_inputs.to_csv(\"input_datasets_overview.csv\", index=False)\n",
    "print(\"Saved table to input_datasets_overview.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754e4ffe",
   "metadata": {},
   "source": [
    "## 4) Load Cellpose masks and compute centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a61943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confocal centroids: (191, 4) | 2P centroids: (939, 4)\n",
      "[Confocal (HCR)] shape=(155, 2048, 2048) ndim=3 dtype=uint16 min=0 max=191 cells=191\n",
      "[2P (mCherry)] shape=(196, 750, 750) ndim=3 dtype=uint16 min=0 max=939 cells=939\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5635683448746c9808a144801903bb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Stack', options=('Confocal', '2P'), value='Confocal'), IntSlider(v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "is3d = (masks_conf.ndim == 3)\n",
    "assert masks_2p.ndim == masks_conf.ndim, \"Confocal and 2P masks must have same dimensionality (both 2D or both 3D).\"\n",
    "\n",
    "df_conf = compute_centroids(masks_conf)\n",
    "df_2p   = compute_centroids(masks_2p)\n",
    "\n",
    "print(\"Confocal centroids:\", df_conf.shape, \"| 2P centroids:\", df_2p.shape)\n",
    "df_conf.head(), df_2p.head()\n",
    "\n",
    "# Print concise summaries\n",
    "for m, n in [(masks_conf, \"Confocal (HCR)\"), (masks_2p, \"2P (mCherry)\")]:\n",
    "    s = mask_summary(m, n)\n",
    "    print(f\"[{s['name']}] shape={s['shape']} ndim={s['ndim']} dtype={s['dtype']} \"\n",
    "          f\"min={s['min']} max={s['max']} cells={s['n_cells']}\")\n",
    "\n",
    "# Interactive viewer\n",
    "def _browse(which: str = \"Confocal\", z: int = 0):\n",
    "    arr = masks_conf if which == \"Confocal\" else masks_2p\n",
    "    img = safe_slice(arr, z)\n",
    "    plt.figure()\n",
    "    plt.imshow(img, cmap=\"nipy_spectral\", interpolation=\"nearest\")\n",
    "    if arr.ndim == 3:\n",
    "        plt.title(f\"{which} — z={int(np.clip(z, 0, arr.shape[0]-1))}/{arr.shape[0]-1}\")\n",
    "    else:\n",
    "        plt.title(f\"{which} — 2D mask\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Set slider range to cover the larger Z; safe_slice() clamps for the smaller stack.\n",
    "zmax = max(masks_conf.shape[0] if masks_conf.ndim == 3 else 1,\n",
    "           masks_2p.shape[0]   if masks_2p.ndim   == 3 else 1) - 1\n",
    "interact(\n",
    "    _browse,\n",
    "    which=Dropdown(options=[\"Confocal\", \"2P\"], value=\"Confocal\", description=\"Stack\"),\n",
    "    z=IntSlider(min=0, max=max(0, zmax), step=1, value=0, description=\"z-plane\")\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162e6a2c",
   "metadata": {},
   "source": [
    "## 3) Convert centroids to physical units (µm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b51bebd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_conf_um shape: (191, 3), P_2p_um shape: (939, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "P_conf_um = idx_to_um(df_conf, VOX_CONF)\n",
    "P_2p_um   = idx_to_um(df_2p,   VOX_2P)\n",
    "print(f\"P_conf_um shape: {P_conf_um.shape}, P_2p_um shape: {P_2p_um.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f0c7d6",
   "metadata": {},
   "source": [
    "## 4) Apply ANTs transform (confocal → 2P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02d470c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying ANTs transform via ANTsPy...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if HAVE_ANTSPY:\n",
    "    print(\"Applying ANTs transform via ANTsPy...\")\n",
    "    P_conf_in_2p_um = apply_ants_transform_to_points(P_conf_um, is3d, ANTs_TRANSFORMS, VOX_CONF, VOX_2P)\n",
    "else:\n",
    "    print(\"ANTsPy not available. Exporting confocal centroids to CSV for antsApplyTransformsToPoints...\")\n",
    "    export_csv = \"conf_centroids_input_points.csv\"\n",
    "    # antsApplyTransformsToPoints expects columns: x,y,(z) in index units of the MOVING image.\n",
    "    moving_idx = um_to_idx_df(P_conf_um, VOX_CONF, is3d)\n",
    "    moving_idx.to_csv(export_csv, index=False)\n",
    "    print(f\"Wrote {export_csv}.\")\n",
    "    print(\"\"\"\n",
    "Next steps (outside Python):\n",
    "  antsApplyTransformsToPoints -d {2 if not is3d else 3}     -i conf_centroids_input_points.csv     -o conf_centroids_in_2p_index.csv     -t { ' -t '.join(ANTs_TRANSFORMS) }     --precision float\n",
    "Then re-import here:\n",
    "    fixed_idx = pd.read_csv(\"conf_centroids_in_2p_index.csv\")\n",
    "    P_conf_in_2p_um = idx_df_to_um(fixed_idx, VOX_2P, is3d)\n",
    "\"\"\".strip())\n",
    "    P_conf_in_2p_um = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf01273",
   "metadata": {},
   "source": [
    "## 5) Match cells and compute distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0955e3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   conf_label  twoP_label  distance_um  within_gate\n",
      "0           1          85   556.063718        False\n",
      "1           2          85   601.182458        False\n",
      "2           3          57   606.645041        False\n",
      "3           4          57   595.958111        False\n",
      "4           5          57   631.167258        False\n",
      "Summary: {\n",
      "  \"N_total\": 191,\n",
      "  \"N_within_gate\": 0,\n",
      "  \"frac_within_gate\": 0.0,\n",
      "  \"median_um\": NaN,\n",
      "  \"p90_um\": NaN\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if P_conf_in_2p_um is None:\n",
    "    raise RuntimeError(\"Transformed confocal centroids not available yet. Complete the ANTs step then re-run.\")\n",
    "\n",
    "labels_conf = df_conf[\"label\"].to_numpy()\n",
    "labels_2p   = df_2p[\"label\"].to_numpy()\n",
    "\n",
    "if MATCH_METHOD == \"nn\":\n",
    "    dists, nn = nearest_neighbor_match(P_conf_in_2p_um, P_2p_um)\n",
    "    matched_twoP_labels = labels_2p[nn]\n",
    "    matched_conf_labels = labels_conf\n",
    "elif MATCH_METHOD == \"hungarian\":\n",
    "    dists, col_ind, row_ind = hungarian_match(P_conf_in_2p_um, P_2p_um, max_cost=np.inf)\n",
    "    # reorder labels to align with row_ind\n",
    "    matched_conf_labels = labels_conf[row_ind]\n",
    "    matched_twoP_labels = labels_2p[col_ind]\n",
    "else:\n",
    "    raise ValueError(\"MATCH_METHOD must be 'nn' or 'hungarian'\")\n",
    "\n",
    "valid = dists <= MAX_DISTANCE_UM\n",
    "\n",
    "matches = pd.DataFrame({\n",
    "    \"conf_label\": matched_conf_labels,\n",
    "    \"twoP_label\": matched_twoP_labels,\n",
    "    \"distance_um\": dists,\n",
    "    \"within_gate\": valid\n",
    "})\n",
    "print(matches.head())\n",
    "\n",
    "summary = summarize_distances(dists, valid)\n",
    "print(\"Summary:\", json.dumps(summary, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e131d848",
   "metadata": {},
   "source": [
    "## 6) Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6154ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAHHCAYAAACle7JuAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAANOVJREFUeJzt3Qd0FOX6x/EnEAg9dJLQu3QQEZEiChKKhXL9C5YLiFxBUAFFiYIUvcLVK2BBEAvoFeWi0qVIR6RIEbkgIkFQRJpACAEJbf7nec+ZPbtLOkl23/D9nLOEnZ2dfXdmdue3b5kJcRzHEQAAAAvlCnQBAAAAMoogAwAArEWQAQAA1iLIAAAAaxFkAACAtQgyAADAWgQZAABgLYIMAACwFkEGAABYiyCDHGfUqFESEhKSLa/VunVrc3OtXr3avPYXX3yRLa/fq1cvqVSpkgSzhIQEefTRRyUiIsKsm0GDBsn1RLePbqfUTJ8+3ayfAwcOZNq+oMvTzwOQkxFkENTcL3f3li9fPomKipLo6Gh588035cyZM5nyOn/88Yf5wt++fbsEm2AuW1q88sorZjv2799f/vOf/8jDDz8sweTcuXNm/WoIhcinn34qEydOZFXAGqGBLgCQFmPGjJHKlSvLxYsX5ciRI+ago7/sx48fL/Pnz5f69et75h0+fLgMGzYs3WFh9OjR5hdtw4YN0/y8r7/+Oss3YEple++99+TKlSsSzFauXCm33HKLjBw5UoKRBhldv8q7di2z7NmzR3LlCsxvxr/++ktCQ0PTHWR27tx53dWcwV4EGVihQ4cOctNNN3nux8TEmAPkXXfdJffcc4/s3r1b8ufPbx7TL+70fnln5OBXoEAByZs3rwRSnjx5JNgdO3ZMateuLTnF2bNnpWDBgmmePywsTAJFazCBnI6mJVjrjjvukBEjRsivv/4qn3zySYp9ZJYtWyYtWrSQokWLSqFChaRmzZry/PPPm8e0dqdJkybm/7179/Y0Y2lziPsrvW7durJ161Zp1aqVCTDuc/37yLguX75s5tF+IXrQ07B18ODBNPWd8F5mamVLql+EHmiffvppKV++vDmI6nv997//Lf4XutflDBw4UObOnWven85bp04dWbJkSZoDSp8+faRMmTLmgNmgQQP56KOPruovtH//fvnqq688ZU+tD4huy5tvvtms52LFipl17l/ztXjxYmnZsqVZt4ULF5ZOnTrJrl27fObRdaPb+tChQ9K5c2fz/1KlSskzzzxjto/Ssug0pbUybhndfiXuMvbt2ycdO3Y0r/Xggw+maz0ntZ21rLr/avguV66cvPzyy+mqWXO3ma53/Ttnzpwk5/PvI6NNsVrTomXSMpcuXVruvPNO2bZtm3lc9zvdVvqZcteFu39duHBBXnzxRWncuLGEh4ebda/bYNWqVT6vqetUn6frYurUqVK1alXzWrofb968+aoy/vTTT/J///d/Zjvo+tD1+MILL/jMo9vwkUceMfuau59++OGHVy3rrbfeMo+5+47++NEaJuRs1MjAatrfQgODHuj69u2b5Dx60NCaG21+0iYq/SKMjY2Vb7/91jxeq1YtM12/pP/xj3+YL2d16623epZx4sQJUyvUvXt3eeihh8wXakr++c9/mi/z5557zhzwtc9B27ZtTT8Xt+YoLdJSNm96ENXQpAcXDRnaFLV06VIZOnSoORhMmDDBZ/5169bJ7Nmz5fHHHzcHae131K1bN/ntt9+kRIkSKTZZ6EFP16OGIW32+/zzz80BOy4uTp566ilTdu0TM3jwYHOw1oO+coNDUjRM6IFX35++b63x2rRpk6l9a9eunZlHl9mzZ0/TT+pf//qXqR2bPHmyCarff/+9T7DTwKLzNW3a1BxYly9fLq+//ro5uGqfHS2LPlf/36VLF+natat5nndT5aVLl8wydPm6DD1Ipnc9e9Om0dtvv90sV5tANRDoAT+t+4Xu67qNtJZr7NixZt/UkKvrODX9+vUzHdF1m+nz9bm6D2iN5o033mgCxOnTp+X333/3vAcNcio+Pl7ef/996dGjh/msaSj64IMPzLr57rvvrmr21ACh8zz22GPms/Dqq6+a9fvLL794ahJ37Nhh9mm9r/u3bjsNjQsWLDCfIXX06FHTNOkGb91mGmR1vWuZ3CYwbWZ98skn5W9/+5vZ/86fP2+Wr/vPAw88kKZ1C0s5QBCbNm2a/rx1Nm/enOw84eHhTqNGjTz3R44caZ7jmjBhgrl//PjxZJehy9d59PX83XbbbeaxKVOmJPmY3lyrVq0y85YtW9aJj4/3TJ81a5aZ/sYbb3imVaxY0enZs2eqy0ypbPp8XY5r7ty5Zt6XX37ZZ76//e1vTkhIiBMbG+uZpvPlzZvXZ9oPP/xgpr/11ltOSiZOnGjm++STTzzTLly44DRr1swpVKiQz3vX8nXq1MlJzd69e51cuXI5Xbp0cS5fvuzz2JUrV8zfM2fOOEWLFnX69u3r8/iRI0fMfuA9XdeNlnHMmDE+8+q+0rhxY8993S90Pt1v/LnLGDZsmM/09Kxn/+08aNAg89xNmzZ5ph07dsyUX6fv378/xfXUsGFDJzIy0omLi/NM+/rrr81zvfcF5f++9DUGDBiQ4vJ1W/kvR126dMlJTEz0mXbq1CmnTJkyziOPPOKZpuXX1y1RooRz8uRJz/R58+aZ6QsWLPBMa9WqlVO4cGHn119/TXJ7qz59+pj3++eff/rM0717d/N+zp07Z+7fe++9Tp06dVJ8b8iZaFqC9fQXY0qjl7Q5Sc2bNy/DHWO1Fkd/9abV3//+d1PD4dJfiZGRkbJo0SLJSrr83Llzm1+m3rQ2RI9r+kvWm9YSae2ES2siihQpYn41p/Y62mymv85d+qtaX1eHW69ZsybdZdfmEt0+Wvvk3znWbSrUJkKt8dHX/fPPPz03fc9a6+LfzOHWQnjTGoDU3p8/rbG5lvXs/1ytYdDmM5fWMrhNVik5fPiwqdXTGilt3nFp81Ba+iHpZ0FrKLQDeXrp+3X7hOl2OnnypKlV0uYbt2nK2/3332+ad1xubaK77o8fPy5r1641TUYVKlRIcnvruvzyyy/l7rvvNv/33uZaE6S1R+5r63vTmqSkmq+QsxFkYD09cHqHhqS+UJs3b27OZaJNQto8NGvWrHSFmrJly6arY2/16tWv+mKuVq1ahs8Rklbat0GHp/uvD23mcR/35n8AUXrwOXXqVKqvo+/RP3Ak9zppoU0KuryUDsh79+41f7V/iR78vW/a5KLNeN60D4l/U1Za3p837Tju32yT3vXs/1z//UNp35DUuMvN6PO1eUdHJGm/Hg1S2oyXnlCnfaA07Op61aZHXbfap0YDhT//fcsNNe66d19X+/gkR8OOBldtevPf3u4PC3ebazOu/qjR96XrZ8CAAZ7mY+Rs9JGB1fQXmH6JakhIjvY90F9++mtdv3S1M+t///tfczDUg5/+0kxNevq1pFVyJ+3Tfh1pKVNmSO51/DusBgs3fGo/Ga0R8uc/Wi0z1qPWxgVq+HRm0061WjOinYN133/ttddMPyPtJ6V9wFLrhK19oLTjtPYF0o7Cun61n46G0KzYt9ztrf3StBYqKW5/Jg2ROtR94cKF5jOuNTnvvPOOqeFzh9cjZyLIwGp6QFNazZwSPRC1adPG3PTcM3qSNu3YqOFGm1cy+0zAbs2B95e3doz17kSqv1D112ZSv7qrVKniuZ+eslWsWNF0aNWmNu/aAh0Z4j6eGXQ52pFSDzTeB/lreR1t4tLl/fjjj8mey8dtBtODqG63zJCRbX8t61kf898/lB6E0/K6KqPPV9rEqZ279aa1GdrJVzvWukEmufWhnYR1v9TQ4z1PRs8P5O7jWkOUHK150fWr4T4t21s7TmsNrN50lJV2Ltb3pqdrYCh6zpUzfmbguqQjWV566SUzYial/gXalu/PPVAmJiaav+55QZIKFhnx8ccf+/Tb0YOA9m/w/tWrB+WNGzeaL1yX/pr0H6adnrLpEGH90n/77bd9pusIFD34pParO630dXT0jdZsubS/hA5/1er92267Ld3L1F/6Gop0tJJ/s5/7K14Dq/bh0SCqJ0dMqikivXQUUnq3/bWsZ32ubncd6eNd7hkzZqQphOi+q0083s052ndIA2BKtLz+TUAaCLWJzP0cuPtbUk1Fbg2Ld42K9rfZsGGDZISGFB1ar8OodZScN/c19DV1hJbWriQVeLy3t47A8qZNwdpMqctKal9BzkGNDKygnSf1164eLHU4poYY/fLWX6h6Zt+Ufm3pgVGblvRcIzq//grVKmft96BDat1QoZ0Fp0yZYn4B6pe5dh7VkJQRxYsXN8vWdnwtrw6/1uYv7yHi2mdHA0779u1Nlb9Wz2v1vXfn2/SWTTtF6tBerW3S/jh6bhdtQtCOzjpM1X/ZGaVDZd99913T1KDn19Fhs/petE+CvteU+iwlR9ePllvDqTZ/6K9pbdbRzpt6sNUmDA0xOlxah91rTYL2d9IDoh4ItdlQ+0L5h4u0NBvqAU9DWY0aNcy2034bKfXduJb1/Oyzz5qaRN3uOkzYHX7t1nKlRteD7su6f2lHWQ3q7vlTtL9YcjRY6z6vHc+1vBo4tVZJ168OSXfpeWJ0XQwZMsSc+0Xn0/erpzDQ2hgdpq6vr+cH0n1S111Kr5sSHe6v70O3pe5Tuk/r+tRt6V6SY9y4cabmVPd5/fzo6+l71k6+Wn73h4oOz9fmRt0HtC+cDinXfUHLmpH9ERYJ9LApIC3Dr92bDheOiIhw7rzzTjOU2XuYb3LDr1esWGGGZkZFRZnn698ePXo4P//8s8/zdHho7dq1ndDQUJ/hzjoUOrlhnckNv/7ss8+cmJgYp3Tp0k7+/PnNkFb/Iabq9ddfN0O1w8LCnObNmztbtmy5apkplc1/+LU7RHnw4MHmfebJk8epXr2689prr/kMaVW6nKSG4iY3LNzf0aNHnd69ezslS5Y067VevXpJDhFP6/Br14cffmiGSOs6KVasmFkXy5Yt85lH13N0dLQZfpsvXz6natWqTq9evcz6c+l7KFiwYKr7h1q/fr0Zkq3vw3vIcnLLSM96Tmp97tixw7wvLbtu/5deesn54IMP0jT8Wn355ZdOrVq1zDrS/WL27NlJ7gve70WHTg8dOtRp0KCBGfKs70v//8477/g8JyEhwXnggQfMMHfvId36vl555RVzX19Xt9HChQuvel13+LWuC39JDXPfuXOnGXKvr6fro2bNms6IESOu2td0Xy1fvrxZ1/od0KZNG2fq1Kmeed59910znFuHfWv5dJ/Q93v69OlU1yfsFqL/BDpMAQAAZAR9ZAAAgLUIMgAAwFoEGQAAYC2CDAAAsBZBBgAAWIsgAwAArJXjT4inZwjVK73qCZEy+zT0AAAga+jZYfREjnpCzJSud5bjg4yGGL3SKwAAsI9etsX/CvTXVZBxT02tK0JPbw4AAIJffHy8qYhI7RITOT7IuM1JGmIIMgAA2CW1biF09gUAANYiyAAAAGsRZAAAgLUIMgAAwFoEGQAAYC2CDAAAsBZBBgAAWIsgAwAArEWQAQAA1iLIAAAAaxFkAACAtQgyAADAWgQZAABgLYIMAACwFkEGAABYKzTQBQCAa1Fp2FdpnvfAuE6sbCCHoUYGAABYiyADAACsRZABAADWIsgAAABrEWQAAIC1CDIAAMBaBBkAAGAtggwAALBWQIPM2LFjpUmTJlK4cGEpXbq0dO7cWfbs2eMzT+vWrSUkJMTn1q9fv4CVGQAABI+ABpk1a9bIgAEDZOPGjbJs2TK5ePGitGvXTs6ePeszX9++feXw4cOe26uvvhqwMgMAgOAR0EsULFmyxOf+9OnTTc3M1q1bpVWrVp7pBQoUkIiIiACUEAAABLOg6iNz+vRp87d48eI+02fMmCElS5aUunXrSkxMjJw7dy7ZZSQmJkp8fLzPDQAA5ExBc9HIK1euyKBBg6R58+YmsLgeeOABqVixokRFRcmOHTvkueeeM/1oZs+enWy/m9GjR2djyQEAQKCEOI7jSBDo37+/LF68WNatWyflypVLdr6VK1dKmzZtJDY2VqpWrZpkjYzeXFojU758eVPbU6RIkSwrP4DA4OrXQM6kx+/w8PBUj99BUSMzcOBAWbhwoaxduzbFEKOaNm1q/iYXZMLCwswNAADkfAENMloZ9MQTT8icOXNk9erVUrly5VSfs337dvM3MjIyG0oIAACCWUCDjA69/vTTT2XevHnmXDJHjhwx07UqKX/+/LJv3z7zeMeOHaVEiRKmj8zgwYPNiKb69esHsugAAOB6DzKTJ0/2nPTO27Rp06RXr16SN29eWb58uUycONGcW0b7unTr1k2GDx8eoBIDAIBgEvCmpZRocNGT5gEAAAT9eWQAAADSgyADAACsRZABAADWIsgAAABrEWQAAIC1CDIAAMBaBBkAAGCtoLjWEgBk9EKQAK5v1MgAAABrEWQAAIC1CDIAAMBaBBkAAGAtggwAALAWQQYAAFiLIAMAAKxFkAEAANYiyAAAAGsRZAAAgLUIMgAAwFoEGQAAYC2CDAAAsBZBBgAAWIsgAwAArEWQAQAA1iLIAAAAaxFkAACAtQgyAADAWgQZAABgLYIMAACwFkEGAABYiyADAACsRZABAADWIsgAAABrEWQAAIC1CDIAAMBaBBkAAGAtggwAALAWQQYAAFiLIAMAAKxFkAEAANYiyAAAAGsRZAAAgLUIMgAAwFoEGQAAYC2CDAAAsBZBBgAAWIsgAwAArEWQAQAA1iLIAAAAaxFkAACAtQgyAADAWgQZAABgLYIMAACwFkEGAABYiyADAACsRZABAADWIsgAAABrBTTIjB07Vpo0aSKFCxeW0qVLS+fOnWXPnj0+85w/f14GDBggJUqUkEKFCkm3bt3k6NGjASszAAAIHgENMmvWrDEhZePGjbJs2TK5ePGitGvXTs6ePeuZZ/DgwbJgwQL5/PPPzfx//PGHdO3aNZDFBgAAQSI0kC++ZMkSn/vTp083NTNbt26VVq1ayenTp+WDDz6QTz/9VO644w4zz7Rp06RWrVom/Nxyyy0BKjkAAAgGQdVHRoOLKl68uPmrgUZradq2beuZ54YbbpAKFSrIhg0bklxGYmKixMfH+9wAAEDOFDRB5sqVKzJo0CBp3ry51K1b10w7cuSI5M2bV4oWLeozb5kyZcxjyfW7CQ8P99zKly+fLeUHAADXcZDRvjI7d+6UmTNnXtNyYmJiTM2Oezt48GCmlREAAASXgPaRcQ0cOFAWLlwoa9eulXLlynmmR0REyIULFyQuLs6nVkZHLeljSQkLCzM3AACQ8wW0RsZxHBNi5syZIytXrpTKlSv7PN64cWPJkyePrFixwjNNh2f/9ttv0qxZswCUGAAABJPQQDcn6YikefPmmXPJuP1etG9L/vz5zd8+ffrIkCFDTAfgIkWKyBNPPGFCDCOWAABAQIPM5MmTzd/WrVv7TNch1r169TL/nzBhguTKlcucCE9HJEVHR8s777wTkPICAIDgEhropqXU5MuXTyZNmmRuAAAAQTlqCQAAIL0IMgAAwFoEGQAAYC2CDAAAsBZBBgAAWIsgAwAArEWQAQAA1iLIAAAAaxFkAACAtQgyAADAWgQZAABgLYIMAACwFkEGAABYiyADAACsRZABAADWIsgAAABrEWQAAIC1CDIAAMBaBBkAAGAtggwAALAWQQYAAFiLIAMAAKxFkAEAANYiyAAAAGsRZAAAgLUIMgAAwFoEGQAAYC2CDAAAsBZBBgAAWIsgAwAArEWQAQAA1iLIAAAAaxFkAACAtQgyAADAWgQZAABgLYIMAACwFkEGAABYiyADAACsRZABAADWIsgAAABrEWQAAIC1CDIAAMBaBBkAAGAtggwAALAWQQYAAFiLIAMAAKxFkAEAANYiyAAAAGsRZAAAgLUIMgAAwFoEGQAAYC2CDAAAsBZBBgAAWIsgAwAArEWQAQAA1iLIAAAAawU0yKxdu1buvvtuiYqKkpCQEJk7d67P47169TLTvW/t27cPWHkBAEBwCWiQOXv2rDRo0EAmTZqU7DwaXA4fPuy5ffbZZ9laRgAAELxCA/niHTp0MLeUhIWFSURERLaVCQAA2CPo+8isXr1aSpcuLTVr1pT+/fvLiRMnAl0kAAAQJAJaI5MabVbq2rWrVK5cWfbt2yfPP/+8qcHZsGGD5M6dO8nnJCYmmpsrPj4+G0sMAACCvkamSpUqSdaMxMXFmccyS/fu3eWee+6RevXqSefOnWXhwoWyefNmU0uTnLFjx0p4eLjnVr58+UwrDwAAyAFB5sCBA3L58uWrpmtNyKFDhySraEgqWbKkxMbGJjtPTEyMnD592nM7ePBglpUHAABY1LQ0f/58z/+XLl1qajxcGmxWrFghlSpVkqzy+++/m5qgyMjIFDsH6w0AAOR86Qoy2ryj9HwuPXv29HksT548JsS8/vrraV5eQkKCT+3K/v37Zfv27VK8eHFzGz16tHTr1s2MWtI+Ms8++6xUq1ZNoqOj01NsAACQQ6UryFy5csX81c632ldFm3muxZYtW+T222/33B8yZIj5qyFp8uTJsmPHDvnoo49M3xs9aV67du3kpZdeosYFAABkfNSS1pxkhtatW4vjOMk+rs1XAAAAmT78WvvD6O3YsWOemhrXhx9+mNHFAgAAZG2Q0b4rY8aMkZtuusl0vNU+MwAAAFYEmSlTpsj06dPl4YcfzvwSAQAAZOV5ZC5cuCC33nprRp4KAAAQ2CDz6KOPyqeffpp5pQAAAMiupqXz58/L1KlTZfny5VK/fn1zDhlv48ePz8hiAQAAsj7I6PldGjZsaP6/c+dOn8fo+AsAAII6yKxatSrzS3IdqDTsqzTPe2BcpywtCxCs+z4AZHkfGQAAAGtrZPSyAik1Ia1cufJaygQAAJB1QcbtH+O6ePGiudij9pfxv5gkAABAUAWZCRMmJDl91KhR5orWAAAA1vWReeihh7jOEgAAsDPIbNiwQfLly5eZiwQAAMjcpqWuXbv63HccRw4fPixbtmyRESNGZGSRAAAA2RNkwsPDfe7nypVLatasaa6I3a5du4wsEgAAIHuCzLRp0zLyNAAAgMAHGdfWrVtl9+7d5v916tSRRo0aZVa5AAAAsibIHDt2TLp37y6rV6+WokWLmmlxcXHmRHkzZ86UUqVKZWSxAAAAWT9q6YknnpAzZ87Irl275OTJk+amJ8OLj4+XJ598MiOLBAAAyJ4amSVLlsjy5culVq1anmm1a9eWSZMm0dkXAAAEd43MlStXJE+ePFdN12n6GAAAQNAGmTvuuEOeeuop+eOPPzzTDh06JIMHD5Y2bdpkZvkAAAAyN8i8/fbbpj9MpUqVpGrVquZWuXJlM+2tt97KyCIBAACyp49M+fLlZdu2baafzE8//WSmaX+Ztm3bZmRxAAAAWV8js3LlStOpV2teQkJC5M477zQjmPTWpEkTcy6Zb775JmMlAQAAyMogM3HiROnbt68UKVIkycsWPPbYYzJ+/Pj0lgEAACDrg8wPP/wg7du3T/Zxvc6Snu0XAAAg6ILM0aNHkxx27QoNDZXjx49nRrkAAAAyN8iULVvWnME3OTt27JDIyMj0LBIAACB7gkzHjh1lxIgRcv78+ase++uvv2TkyJFy1113Zbw0AAAAWTX8evjw4TJ79mypUaOGDBw4UGrWrGmm6xBsvTzB5cuX5YUXXkjPIgEAALInyJQpU0bWr18v/fv3l5iYGHEcx0zXodjR0dEmzOg8AAAAQXlCvIoVK8qiRYvk1KlTEhsba8JM9erVpVixYllTQgAAgMw8s6/S4KInwQMAALDqWksAAADBgCADAACsRZABAADWIsgAAABrEWQAAIC1CDIAAMBaBBkAAGAtggwAALAWQQYAAFiLIAMAAKxFkAEAANYiyAAAAGsRZAAAwPV39WsAsE2lYV+led4D4zplaVkAZA5qZAAAgLUIMgAAwFoEGQAAYC2CDAAAsBZBBgAAWIsgAwAArEWQAQAA1iLIAAAAawU0yKxdu1buvvtuiYqKkpCQEJk7d67P447jyIsvviiRkZGSP39+adu2rezduzdg5QUAAMEloEHm7Nmz0qBBA5k0aVKSj7/66qvy5ptvypQpU2TTpk1SsGBBiY6OlvPnz2d7WQEAQPAJ6CUKOnToYG5J0dqYiRMnyvDhw+Xee+810z7++GMpU6aMqbnp3r17NpcWAAAEm6DtI7N//345cuSIaU5yhYeHS9OmTWXDhg3JPi8xMVHi4+N9bgAAIGcK2otGaohRWgPjTe+7jyVl7NixMnr0aLEdF7cDAMDiGpmMiomJkdOnT3tuBw8eDHSRAADA9RZkIiIizN+jR4/6TNf77mNJCQsLkyJFivjcAABAzhS0QaZy5comsKxYscIzTfu76OilZs2aBbRsAAAgOAS0j0xCQoLExsb6dPDdvn27FC9eXCpUqCCDBg2Sl19+WapXr26CzYgRI8w5Zzp37hzIYgMAgCAR0CCzZcsWuf322z33hwwZYv727NlTpk+fLs8++6w518w//vEPiYuLkxYtWsiSJUskX758ASw1AAAIFgENMq1btzbni0mOnu13zJgx5gYAAGBNHxkAAIDUEGQAAIC1CDIAAMBaBBkAAGAtggwAALAWQQYAAFiLIAMAAKxFkAEAANYiyAAAAGsRZAAAgLUIMgAAwFoEGQAAYC2CDAAAsBZBBgAAWIsgAwAArEWQAQAA1iLIAAAAaxFkAACAtQgyAADAWgQZAABgrdBAFwCAnSoN+yrQRcB1KD373YFxnbK0LAgO1MgAAABrEWQAAIC1CDIAAMBaBBkAAGAtggwAALAWQQYAAFiLIAMAAKxFkAEAANYiyAAAAGsRZAAAgLUIMgAAwFoEGQAAYC2CDAAAsBZXvwaATLi6N1davr5wFe7gQY0MAACwFkEGAABYiyADAACsRZABAADWIsgAAABrEWQAAIC1CDIAAMBaBBkAAGAtggwAALAWQQYAAFiLIAMAAKxFkAEAANbiopE5ABe3AwBcr6iRAQAA1iLIAAAAaxFkAACAtQgyAADAWgQZAABgLYIMAACwFkEGAABYiyADAACsRZABAADWCuogM2rUKAkJCfG53XDDDYEuFgAACBJBf4mCOnXqyPLlyz33Q0ODvsgAACCbBH0q0OASERER6GIAAIAgFNRNS2rv3r0SFRUlVapUkQcffFB+++23FOdPTEyU+Ph4nxsAAMiZgrpGpmnTpjJ9+nSpWbOmHD58WEaPHi0tW7aUnTt3SuHChZN8ztixY818wXjVaQAAkLmCukamQ4cOct9990n9+vUlOjpaFi1aJHFxcTJr1qxknxMTEyOnT5/23A4ePJitZQYAANknqGtk/BUtWlRq1KghsbGxyc4TFhZmbgAAIOcL6hoZfwkJCbJv3z6JjIwMdFEAAEAQCOog88wzz8iaNWvkwIEDsn79eunSpYvkzp1bevToEeiiAQCAIBDUTUu///67CS0nTpyQUqVKSYsWLWTjxo3m/wAAAEEdZGbOnBnoIgAAgCAW1E1LAAAAKSHIAAAAaxFkAACAtQgyAADAWgQZAABgLYIMAACwFkEGAABYK6jPI4OcK71XDj8wrlOWlQUAYC9qZAAAgLUIMgAAwFoEGQAAYC2CDAAAsBZBBgAAWIsgAwAArEWQAQAA1iLIAAAAaxFkAACAtQgyAADAWgQZAABgLYIMAACwFheNvA6l54KNXKwxOC+iietnG/IZtP8zmJXfuZX4PqdGBgAA2IumJQAAYC2CDAAAsBZBBgAAWIsgAwAArEWQAQAA1iLIAAAAaxFkAACAtQgyAADAWgQZAABgLYIMAACwFkEGAABYiyADAACsxdWvYcWVVbOqHMFyVVoAQMZQIwMAAKxFkAEAANYiyAAAAGsRZAAAgLUIMgAAwFoEGQAAYC2CDAAAsBZBBgAAWIsgAwAArEWQAQAA1iLIAAAAaxFkAACAtbhoJDJNsFwkMavKESzvD9eXrNzvsuoCq7BfpSC5YHBaUCMDAACsRZABAADWIsgAAABrEWQAAIC1CDIAAMBaBBkAAGAtggwAALAWQQYAAFjLiiAzadIkqVSpkuTLl0+aNm0q3333XaCLBAAAgkDQB5n//ve/MmTIEBk5cqRs27ZNGjRoINHR0XLs2LFAFw0AAARY0AeZ8ePHS9++faV3795Su3ZtmTJlihQoUEA+/PDDQBcNAAAEWFAHmQsXLsjWrVulbdu2nmm5cuUy9zds2BDQsgEAgMAL6otG/vnnn3L58mUpU6aMz3S9/9NPPyX5nMTERHNznT592vyNj4/P9PJdSTyX6csEgOySnu9FG7/vbHx/6T1WXUlHubNqfWTF8dV7uY7j2BtkMmLs2LEyevToq6aXL18+IOUBgGAVPlFyNBvfX1aWOXyinev5zJkzEh4ebmeQKVmypOTOnVuOHj3qM13vR0REJPmcmJgY0znYdeXKFTl58qSUKFFCQkJCsiQxakg6ePCgFClSJNOXD7aDTfg8BB7bIDiwHa6d1sRoiImKikpxvqAOMnnz5pXGjRvLihUrpHPnzp5govcHDhyY5HPCwsLMzVvRokWzvKwaYggygcd2CA5sh8BjGwQHtsO1Sakmxoogo7R2pWfPnnLTTTfJzTffLBMnTpSzZ8+aUUwAAOD6FvRB5v7775fjx4/Liy++KEeOHJGGDRvKkiVLruoADAAArj9BH2SUNiMl15QUaNqMpSfr82/OAtvhesTnIfDYBsGB7ZB9QpzUxjUBAAAEqaA+IR4AAEBKCDIAAMBaBBkAAGAtggwAALAWQSaZyxw0adJEChcuLKVLlzYn49uzZ4/PPOfPn5cBAwaYMwYXKlRIunXrdtUZiH/77Tfp1KmTuVq3Lmfo0KFy6dKlrN2iOcjkyZOlfv36nhNKNWvWTBYvXux5nG2Q/caNG2fOkD1o0CC2QzYaNWqUWe/etxtuuIFtEACHDh2Shx56yHz358+fX+rVqydbtmzxPK7jZ/R0IZGRkeZxvcjx3r17fZahZ5t/8MEHzfeanrC1T58+kpCQEIB3k0PoqCX4io6OdqZNm+bs3LnT2b59u9OxY0enQoUKTkJCgmeefv36OeXLl3dWrFjhbNmyxbnlllucW2+91fP4pUuXnLp16zpt27Z1vv/+e2fRokVOyZIlnZiYGFZ3Gs2fP9/56quvnJ9//tnZs2eP8/zzzzt58uQx24VtkP2+++47p1KlSk79+vWdp556yjOdz0LWGzlypFOnTh3n8OHDntvx48fZBtns5MmTTsWKFZ1evXo5mzZtcn755Rdn6dKlTmxsrGeecePGOeHh4c7cuXOdH374wbnnnnucypUrO3/99Zdnnvbt2zsNGjRwNm7c6HzzzTdOtWrVnB49emT328kxCDJpcOzYMR2i7qxZs8bcj4uLMwfUzz//3DPP7t27zTwbNmww9zW45MqVyzly5IhnnsmTJztFihRxEhMTM39LXieKFSvmvP/++2yDbHbmzBmnevXqzrJly5zbbrvNE2T4LGRfkNEDX1LYBtnnueeec1q0aJHs41euXHEiIiKc1157zWf7hIWFOZ999pm5/+OPP5pjxebNmz3zLF682AkJCXEOHTqUxe8gZ6JpKQ1Onz5t/hYvXtz83bp1q1y8eNFUGbq0mrdChQqyYcMGc1//apWj9xmIo6OjzYXEdu3aldkVazne5cuXZebMmebyFNrExDbIXtqMqs2k3vu8YjtkH22e0IvnValSxTRLaNM12yB7zZ8/31wu57777jPdBRo1aiTvvfee5/H9+/ebM9B7f070WkFNmzb1OTZoc5Iux6Xz58qVSzZt2pTN7yhnIMikQi9Sqf0BmjdvLnXr1jXTdEfVC1r6X4xSQ4s+5s7jfxkF9747D1L3v//9z/RB0rNk9uvXT+bMmSO1a9dmG2QjDZDbtm0zfcf88VnIHnognD59urk8i/Yd0wNmy5YtzZWB2QbZ55dffjHrv3r16rJ06VLp37+/PPnkk/LRRx/5fLcn9d3vfWzQEOQtNDTU/FDm2JCDL1EQ6F+iO3fulHXr1gW6KNelmjVryvbt202t2BdffGEuILpmzZpAF+u6cfDgQXnqqadk2bJlki9fvkAX57rVoUMHz/+1A7wGm4oVK8qsWbNMh1Jk3w9brUl55ZVXzH2tkdHjw5QpU8x3EwKDGpkU6PWdFi5cKKtWrZJy5cp5pkdERMiFCxckLi7OZ34dtaSPufP4j2Jy77vzIHVa81WtWjVp3LixqRFo0KCBvPHGG2yDbKJNR8eOHZMbb7zR/GrUmwbJN9980/xff2nyWch+Whtco0YNiY2N5bOQjXQkktYIe6tVq5anmc/9bk/qu9/72KCfKW86mlVHMnFsyBiCTBK0E7SGGG3GWLlypVSuXNnncT2o5smTR1asWOGZpsOzdWfW/htK/2qziPcOq79qdbid/wcB6ftFlJiYyDbIJm3atDH7sdaKuTf9Rap9NNz/81nIfjpUd9++febAyvdR9tEuBv6n4vj5559N7ZjSY4WGEe9jg/aL1L4v3scG/RGsPxJcepzR7zataUMGBLq3cTDq37+/GT63evVqn+GO586d8xlyqkOyV65caYZfN2vWzNz8h1+3a9fODOFesmSJU6pUKYZfp8OwYcPMSLH9+/c7O3bsMPe1Z//XX3/NNggg71FLis9C1nv66afN95F+Fr799ltzWgc9nYOOqGQbZO8pCEJDQ51//vOfzt69e50ZM2Y4BQoUcD755BOf4ddFixZ15s2bZ7637r333iSHXzdq1MgM4V63bp0ZEcjw64wjyCS1UkSSvOm5ZVy6Uz7++ONmOLDuyF26dDFhx9uBAwecDh06OPnz5zdfOvpldPHixWvYXNeXRx55xJyzIW/evCYEtmnTxhNiFNsgOIIM2yHr3X///U5kZKT5LJQtW9bc9z53Cdsg+yxYsMD8SNUh1TfccIMzderUq4ZgjxgxwilTpoyZR7+39DxY3k6cOGGCS6FChcwpOXr37m1OcYCMCdF/MlKTAwAAEGj0kQEAANYiyAAAAGsRZAAAgLUIMgAAwFoEGQAAYC2CDAAAsBZBBgAAWIsgAyDDVq9eLSEhIVddd8ybXrXZ/0rxqTlw4IBZrl4GIa2vYzM97b2e2l6vZp2V/vzzT3Pl5d9//z1LXwfITgQZIEgcOXJEnnjiCalSpYqEhYVJ+fLl5e677/a5bktmaN26tQwaNChTlnXrrbfK4cOHJTw8PFOWlxmvY2PoiYmJMdu+cOHCWfo6JUuWlL///e8ycuTILH0dIDsRZIAgoDUQevE/vXjca6+9Zi7UuGTJErn99ttlwIAB2V4ePeG3XpE3LVcn15oEDQ5ZKbteJxD0YrMLFy6UXr16Zcvr9e7dW2bMmGGutgzkBAQZIAg8/vjj5iD93XffSbdu3aRGjRpSp04dGTJkiGzcuNEzn9YyPProo1KqVClzJfU77rhDfvjhB8/jo0aNkoYNG8p//vMfqVSpkqnB6N69u6fJQg+Wa9askTfeeMO8nt40RLm1GIsXLzaBSmuE1q1bZ640/uSTT5rmiHz58kmLFi1k8+bNKdZ+aFNShQoVpECBAtKlSxc5ceJEqu9f33ejRo3Ma+gVtb///nufx/1f59dffzW1VcWKFZOCBQuadbVo0SLzXjT8KX1Mn+MGBA2GWn5t5ipRooTcdddd5grS/s1Zs2fPNsvQ8jdo0EA2bNjgU5Zvv/3W1Grp4/oa0dHRcurUKfOYXsF47Nix5irI+fPnN8//4osvUnzvs2bNMvOVLVv2qu3obeLEiWabuvR9de7cWV555RUpU6aMeV9jxowxAXTo0KFSvHhxKVeunEybNs1nObquoqKiZM6cOaluF8AGBBkgwPSXsR5kteZFD8r+vPuX3HfffXLs2DETOLZu3So33nijtGnTxufXtR6c586da37l602Dy7hx48xjGmCaNWsmffv2NU01etMmLNewYcPMvLt375b69evLs88+K19++aV89NFHsm3bNqlWrZo5cCf3a37Tpk3Sp08fGThwoOnfooHg5ZdfTvH9JyQkmFBRu3Zt8570IP7MM8+k+BxdVxqy1q5da2qv/vWvf0mhQoXMe9Hyuv1O9P3pe1Znz541wXDLli2muS5XrlwmaGn48PbCCy+Y19fya6Ds0aOHp3ZKp+n61rJqwNGwp4Hq8uXL5nENMR9//LFMmTJFdu3aJYMHD5aHHnrIbIPkfPPNNya8ZYTW4P3xxx9mPYwfP940Gem61ICl26Jfv37y2GOPXdUn5uabbzavC+QIGbzYJIBMsmnTJnN19dmzZ6c43zfffGOulHv+/Hmf6VWrVnXeffdd8/+RI0eaq7HHx8d7Hh86dKjTtGnTZK9erVatWmXKMHfuXM+0hIQEJ0+ePM6MGTM80y5cuOBERUU5r776qs/zTp06Ze7rFX07duzos2y9UnN4eHiy70vLXqJECXMFZ9fkyZPNcr///vskX6devXrOqFGjklye/7zJOX78uJnvf//7n7m/f/9+c//999/3zLNr1y4zbffu3Z7317x58ySXp9tF1/369et9pvfp08c8LzkNGjRwxowZ4zNNt6NO9zZhwgRzNXhXz549zf3Lly97ptWsWdNp2bKl5/6lS5ecggULOp999pnPsgYPHuy0bt062TIBNqFGBgiwtF6AXpuQtPZCm0W09sG97d+/36eJRJsfvDuNRkZGmlqctPCuGdBlXrx4UZo3b+6ZlidPHvNrXmtskqLTmzZt6jNNa4BS4tb+aLNSWp+jzV1a06Nl01qIHTt2pPre9u7da2pXtDO1Nsu5zTTaR8WblsV73Sl3/bk1MkmJjY2Vc+fOyZ133umzfbSGxnv7+Pvrr7983nt6aDOR1iy5tImpXr16nvu5c+c2+4v/9tdmLy0rkBOEBroAwPWuevXqpm/GTz/9lOJ8GmL0wKr9RVJqftKw4U2X7d98kpykmraCkfYT0iaur776Sr7++mvTpPP666+bkT/J0SagihUrynvvvWf6iOg6qVu3rly4cMFnPu/153YudtefBoCUto/SMnn3d1Ha5yilkURuH5uUuM1XyZXVLW9atr82DWo/KyAnoEYGCDDtlKkH5UmTJpl+HP7cDq7aH0aHaIeGhpq+Kt43PRimZwRQUgdFf1WrVjXzaudWl9bQaGdf7SOSlFq1apm+Gd68Oysn9xytUTl//nyan6O0P4z2AdHOuU8//bQJKO77U97vUTsca5+Z4cOHmxoVfc20hAd/WluT3HB4XScaWLSGx3/7ePdD8qednH/88cerph89etTn/i+//CKZZefOneZ1gZyAIAMEAQ0xeuDVZhvtrKrNINrk8uabb3qaWdq2bWv+ryNVtBZCR9msX7/edE7VDqxppU0qGjb0+XqCtORqa7R2pn///mYEjHZG1oOtdhLWJgnt0Jtck4/O++9//9u8h7ffftvcT8kDDzxgag102foaOvpIn58SPQ/O0qVLTbOadkJetWqVCSdKa110edrR+fjx46amRDu/ahPL1KlTTROQdpLVjr8ZOd+LBjkdZabhS2vRJk+ebNajNudpJ2Ht4Kudo7U5Scv21ltvmfvJ0RCrHYf9w6WGVh2FpAFG9wkdiabhK7Wau9To9tNO1e3atbum5QDBgiADBAHtt6EHPR3lo7UL2uShfS30178eKJUenPUg36pVK3MuEB1Ro0OrdSiy9o1IKz3Yat8JrUHQ5gX/PiLedASTDgd/+OGHTY2QhgANEBoMknLLLbeYmhEdKaRDijVwaS1ISrQfyYIFC8zoI60l0GCmo5BSogd9Hbmk4aV9+/ZmXbzzzjvmMW3WGT16tBmBpetFR1BpP5KZM2eaA7iuWw0ber6e9NLX0fek/ZU0dGqwnDdvnqklUy+99JKMGDHCNHW5ZdOmJh2OnZwOHTqY5y9fvtxnupbz559/Nv1gdJnvv/++qW1KbURXarS8Ojy+ZcuW17QcIFiEaI/fQBcCAK73Grn58+ebkKh0CLoOoXcv0ZCZNGxqzZnWhAE5AZ19ASDA9Fwv2hdKT1yYlZcp0Cawrl27mtFbQE5BjQwABJmsrJEBchqCDAAAsBadfQEAgLUIMgAAwFoEGQAAYC2CDAAAsBZBBgAAWIsgAwAArEWQAQAA1iLIAAAAaxFkAACA2Or/AeGO6d0735p3AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Distance histogram\n",
    "plt.figure()\n",
    "plt.hist(matches[\"distance_um\"].to_numpy(), bins=40)\n",
    "plt.xlabel(\"Centroid distance (µm)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Distribution of centroid distances\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a833c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from ipywidgets import interact, FloatSlider, FloatLogSlider, Checkbox\n",
    "except Exception as e:\n",
    "    print(\"ipywidgets not available:\", e)\n",
    "    raise\n",
    "\n",
    "# convenience projections\n",
    "Z2, Y2, X2 = P_2p_um[:,0], P_2p_um[:,1], P_2p_um[:,2]\n",
    "Zc, Yc, Xc = P_conf_in_2p_um[:,0], P_conf_in_2p_um[:,1], P_conf_in_2p_um[:,2]\n",
    "\n",
    "zmin = float(min(Z2.min(), Zc.min()))\n",
    "zmax = float(max(Z2.max(), Zc.max()))\n",
    "default_thick = 4.0  # µm half-thickness on each side of the slider plane\n",
    "\n",
    "def _plot_slice(z_um=0.0, thickness_um=default_thick, show_conf=True, show_2p=True, show_matches=False):\n",
    "    plt.figure()\n",
    "    # 2P points in the slab\n",
    "    if show_2p:\n",
    "        m2 = np.abs(Z2 - z_um) <= thickness_um\n",
    "        plt.scatter(X2[m2], Y2[m2], s=8, label=\"2P\", alpha=0.9)\n",
    "    # confocal→2P points in the slab\n",
    "    if show_conf:\n",
    "        mc = np.abs(Zc - z_um) <= thickness_um\n",
    "        plt.scatter(Xc[mc], Yc[mc], s=8, alpha=0.6, label=\"Conf→2P\")\n",
    "    # optional: draw match lines for pairs whose both endpoints fall in the slab\n",
    "    if show_matches and 'matches' in globals():\n",
    "        # build quick label→coord maps\n",
    "        coord_2p = dict(zip(df_2p[\"label\"].to_numpy(), P_2p_um))\n",
    "        coord_conf = dict(zip(df_conf[\"label\"].to_numpy(), P_conf_in_2p_um))\n",
    "        for _, row in matches.iterrows():\n",
    "            a = coord_conf.get(int(row[\"conf_label\"]))\n",
    "            b = coord_2p.get(int(row[\"twoP_label\"]))\n",
    "            if a is None or b is None:\n",
    "                continue\n",
    "            if (abs(a[0]-z_um) <= thickness_um) and (abs(b[0]-z_um) <= thickness_um):\n",
    "                plt.plot([a[2], b[2]], [a[1], b[1]], linewidth=0.5)\n",
    "\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.xlabel(\"x (µm)\")\n",
    "    plt.ylabel(\"y (µm)\")\n",
    "    plt.title(f\"Centroids near z = {z_um:.2f} µm (±{thickness_um:.2f})\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "interact(\n",
    "    _plot_slice,\n",
    "    z_um=FloatSlider(min=zmin, max=zmax, step=0.5, value=(zmin+zmax)/2, description=\"z (µm)\"),\n",
    "    thickness_um=FloatSlider(min=0.5, max=20.0, step=0.5, value=default_thick, description=\"slab ±µm\"),\n",
    "    show_conf=Checkbox(value=True, description=\"show Conf→2P\"),\n",
    "    show_2p=Checkbox(value=True, description=\"show 2P\"),\n",
    "    show_matches=Checkbox(value=False, description=\"show match lines\"),\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b445f7",
   "metadata": {},
   "source": [
    "## 7) Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5759906e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out_matches_csv = \"centroid_matches.csv\"\n",
    "matches.to_csv(out_matches_csv, index=False)\n",
    "print(f\"Wrote {out_matches_csv}\")\n",
    "\n",
    "out_summary_json = \"qc_summary.json\"\n",
    "with open(out_summary_json, \"w\") as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "print(f\"Wrote {out_summary_json}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0514f849",
   "metadata": {},
   "source": [
    "\n",
    "## Notes & Tips\n",
    "\n",
    "- **Transform direction**: These steps assume your ANTs transform maps *confocal → 2P*. If your files represent the reverse direction, invert them or swap roles.\n",
    "- **Gate selection**: Start with ~1 soma diameter (e.g., 8–12 µm for juvenile zebrafish thalamus). Report fraction within gate, median, p90.\n",
    "- **Outliers**: Investigate > gate by cropping around predicted pairs; often due to segmentation misses or local warp strain.\n",
    "- **Warp health**: Consider computing a log-Jacobian image from the SyN warp and correlating distance outliers with high-deformation regions.\n",
    "- **Reproducibility**: Keep a copy of your exact `VOX_*`, transform filenames, and Cellpose versions alongside the outputs.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "registrations",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
